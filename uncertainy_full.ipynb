{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3ad78fe71283d0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Inplementation of Internal State-based Uncertainty Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b278c24516568ba0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. 数据集预处理：将不同格式的数据集处理成input+gt的格式，方便判断模型的correctness，这一部分的采用固定不可调整的prompt，即Context: Question: Options: Answer:格式\n",
    "2. 生成回复，为每个模型确定一个prompt，一个max_new_tokens数，然后生成回复\n",
    "3. 计算回复部分的correctness指标，判断模型的回复是否正确\n",
    "4. 计算uncertainty指标，包括PE, LN-PE, SAR, Ours\n",
    "5. 计算AUROC，绘制AUROC/Correctness-Threshold曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T00:47:49.321783Z",
     "start_time": "2024-03-26T00:47:29.743883Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/petrelfs/guoyiqiu/miniconda3/envs/mi/lib/python3.9/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Error on querying NVIDIA devices. Use --debug flag to see more details.\n",
      "Driver Not Loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "剩余内存: 492.0 G\n",
      "当前主机名是:SH-IDC1-10-140-0-31\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNVMLError_DriverNotLoaded\u001b[0m                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/mi/lib/python3.9/site-packages/gpustat/cli.py:58\u001b[0m, in \u001b[0;36mprint_gpustat\u001b[0;34m(id, json, debug, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     gpu_stats \u001b[38;5;241m=\u001b[39m \u001b[43mGPUStatCollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/mi/lib/python3.9/site-packages/gpustat/core.py:402\u001b[0m, in \u001b[0;36mGPUStatCollection.new_query\u001b[0;34m(debug, id)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Query the information of all the GPUs on local machine\"\"\"\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m \u001b[43mN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnvmlInit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m log \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mDebugHelper()\n",
      "File \u001b[0;32m~/miniconda3/envs/mi/lib/python3.9/site-packages/pynvml.py:1947\u001b[0m, in \u001b[0;36mnvmlInit\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnvmlInit\u001b[39m():\n\u001b[0;32m-> 1947\u001b[0m     \u001b[43mnvmlInitWithFlags\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mi/lib/python3.9/site-packages/pynvml.py:1937\u001b[0m, in \u001b[0;36mnvmlInitWithFlags\u001b[0;34m(flags)\u001b[0m\n\u001b[1;32m   1936\u001b[0m ret \u001b[38;5;241m=\u001b[39m fn(flags)\n\u001b[0;32m-> 1937\u001b[0m \u001b[43m_nvmlCheckReturn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;66;03m# Atomically update refcount\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mi/lib/python3.9/site-packages/pynvml.py:899\u001b[0m, in \u001b[0;36m_nvmlCheckReturn\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (ret \u001b[38;5;241m!=\u001b[39m NVML_SUCCESS):\n\u001b[0;32m--> 899\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NVMLError(ret)\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mNVMLError_DriverNotLoaded\u001b[0m: Driver Not Loaded",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[2], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m     gpustat\u001b[38;5;241m.\u001b[39mprint_gpustat()\n\u001b[0;32m---> 59\u001b[0m \u001b[43mprint_sys_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 57\u001b[0m, in \u001b[0;36mprint_sys_info\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m当前主机名是:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 57\u001b[0m \u001b[43mgpustat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_gpustat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mi/lib/python3.9/site-packages/gpustat/cli.py:77\u001b[0m, in \u001b[0;36mprint_gpustat\u001b[0;34m(id, json, debug, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m---> 77\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m json:\n",
      "\u001b[0;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/mi/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2095\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2093\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2094\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2095\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2096\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2098\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2099\u001b[0m         \u001b[38;5;66;03m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[1;32m   2100\u001b[0m         \u001b[38;5;66;03m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[1;32m   2101\u001b[0m         \u001b[38;5;66;03m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mi/lib/python3.9/site-packages/IPython/core/ultratb.py:696\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    689\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mi/lib/python3.9/site-packages/IPython/core/ultratb.py:559\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    556\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    557\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    558\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 559\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    563\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    567\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/miniconda3/envs/mi/lib/python3.9/site-packages/IPython/core/ultratb.py:1396\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[0;32m-> 1396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mi/lib/python3.9/site-packages/IPython/core/ultratb.py:1287\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1284\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1286\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/mi/lib/python3.9/site-packages/IPython/core/ultratb.py:1140\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1133\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1138\u001b[0m ):\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1140\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mi/lib/python3.9/site-packages/IPython/core/ultratb.py:1030\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1028\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m   1029\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1030\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   1031\u001b[0m )\n\u001b[1;32m   1033\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1034\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mi/lib/python3.9/site-packages/IPython/core/ultratb.py:1098\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1098\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "os.environ['HF_DATASETS_OFFLINE'] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "import transformer_lens\n",
    "import datasets\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, FactoredMatrix\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "from tqdm.auto import tqdm\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from jaxtyping import Float\n",
    "from functools import partial\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, Dataset, Features, Array2D, Array3D\n",
    "from typing import List, Tuple, Union\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "from time import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from copy import deepcopy\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import util as st_util\n",
    "from transformers import pipeline\n",
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "import math\n",
    "\n",
    "datasets.disable_caching()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "\n",
    "def print_sys_info():\n",
    "    import psutil\n",
    "    import socket\n",
    "    import gpustat\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(\"剩余内存: {} G\".format(memory.available / 1024 / 1024 // 1024))\n",
    "    host_name = socket.gethostname()\n",
    "    print(f\"当前主机名是:{host_name}\")\n",
    "    gpustat.print_gpustat()\n",
    "\n",
    "print_sys_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a702b3ebfcfa6944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T12:00:50.251181Z",
     "start_time": "2024-03-25T12:00:29.303168Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fdd0ccdb0574b128143e20da8474feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/petrelfs/guoyiqiu/miniconda3/envs/mi/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model llama-7b-hf into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# Model Config\n",
    "model_name = \"vicuna-7b-v1.1\"\n",
    "hooked_transformer_name = \"llama-7b-hf\"\n",
    "hf_model_path = os.path.join(os.environ[\"my_models_dir\"], model_name)\n",
    "hf_tokenizer = AutoTokenizer.from_pretrained(hf_model_path)\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(hf_model_path)\n",
    "\n",
    "model = HookedTransformer.from_pretrained_no_processing(hooked_transformer_name, dtype='bfloat16', hf_model=hf_model, tokenizer=hf_tokenizer, default_padding_side='left')\n",
    "\n",
    "# # Aux Models\n",
    "# se_bert_name = \"microsoft/deberta-large-mnli\"\n",
    "# se_bert_pipe = pipeline(\"text-classification\", model=se_bert_name, device=0)\n",
    "\n",
    "# sar_bert_name = 'cross-encoder/stsb-roberta-large'\n",
    "# # sar_bert_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "# sar_bert = SentenceTransformer(sar_bert_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df0eeae0abf3ba21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T11:47:39.553573Z",
     "start_time": "2024-03-25T11:47:39.484901Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_dst = Dataset.load_from_disk(\"eval_results/sciq_short_vicuna-7b-v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dbcaf66fe442cf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T11:49:13.984686Z",
     "start_time": "2024-03-25T11:49:13.954242Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,330):\n",
    "    print(\"\" in test_dst[i]['washed_sampled_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88edd9cca2e9bbfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T14:41:16.342685Z",
     "start_time": "2024-03-24T14:41:16.293234Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Our Method OLD\n",
    "\n",
    "\n",
    "def compute_certainty_vector_mean(train_dst, layers, act_name, batch_size=8):\n",
    "    def get_paired_dst_sciq(train_dst):\n",
    "        tmp_pos = \"Question:{q} Options:{o} The correct answer is:\"\n",
    "        tmp_neg = \"Question:{q} Options:{o} The incorrect answer is:\"\n",
    "    \n",
    "        # sciq_train_dst = sciq_train_dst.filter(lambda x: x['rougel'] > 0.5)\n",
    "    \n",
    "        def get_pos_example(example):\n",
    "            example['input'] = tmp_pos.format(q=example['question'], o=\", \".join(example['options']))\n",
    "            example['washed_output'] = f\"{example['input']}{example['gt']}\"\n",
    "            return example\n",
    "    \n",
    "        def get_neg_example(example, idx):\n",
    "            example['input'] = tmp_neg.format(q=example['question'], o=\", \".join(example['options']))\n",
    "            wrong_options = [opt for opt in example['options'] if opt != example['gt']]\n",
    "            if wrong_options:\n",
    "                random.seed(42 + idx)\n",
    "                wrong_answer = random.choice(wrong_options)\n",
    "            else:\n",
    "                wrong_answer = \"wrong answer\"\n",
    "            example['washed_output'] = f\"{example['input']}{wrong_answer}\"\n",
    "            return example\n",
    "    \n",
    "        dst_pos = train_dst.map(get_pos_example, new_fingerprint=str(time()))\n",
    "        dst_neg = train_dst.map(get_neg_example, with_indices=True, new_fingerprint=str(time()))\n",
    "        return dst_pos, dst_neg\n",
    "    \n",
    "    \n",
    "    def get_paired_dst_coqa(train_dst):\n",
    "        def get_pos_example(example):\n",
    "            example['washed_output'] = f\"{example['input']}The correct answer is {example['gt']}\"\n",
    "            return example\n",
    "    \n",
    "        def get_neg_example(example, idx):\n",
    "            wrong_options = [opt for opt in example['answers']['input_text'] if opt != example['gt']]\n",
    "            if wrong_options:\n",
    "                random.seed(42 + idx)\n",
    "                wrong_answer = random.choice(wrong_options)\n",
    "            else:\n",
    "                wrong_answer = \"wrong answer\"\n",
    "            example['washed_output'] = f\"{example['input']}The wrong answer is {wrong_answer}\"\n",
    "            return example\n",
    "    \n",
    "        dst_pos = train_dst.map(get_pos_example, new_fingerprint=str(time()))\n",
    "        dst_neg = train_dst.map(get_neg_example, with_indices=True, new_fingerprint=str(time()))\n",
    "        return dst_pos, dst_neg\n",
    "    \n",
    "    \n",
    "    def get_paired_dst_triviaqa(train_dst):\n",
    "        def get_pos_example(example):\n",
    "            example['washed_output'] = f\"{example['input']}The correct answer is {example['gt']}\"\n",
    "            return example\n",
    "    \n",
    "        def get_neg_example(example, idx):\n",
    "            next_idx = idx + 1 if idx + 1 < len(train_dst) else 0\n",
    "            wrong_answer = train_dst[next_idx]['gt']\n",
    "            example['washed_output'] = f\"{example['input']}The wrong answer is {wrong_answer}\"\n",
    "            return example\n",
    "    \n",
    "        dst_pos = train_dst.map(get_pos_example, new_fingerprint=str(time()))\n",
    "        dst_neg = train_dst.map(get_neg_example, with_indices=True, new_fingerprint=str(time()))\n",
    "        return dst_pos, dst_neg\n",
    "    \n",
    "    \n",
    "    def get_paired_dst_medmcqa(train_dst):\n",
    "        def get_pos_example(example):\n",
    "            example['washed_output'] = f\"{example['input']}The correct answer is {example['gt']}\"\n",
    "            return example\n",
    "    \n",
    "        def get_neg_example(example, idx):\n",
    "            wrong_options = [opt for opt in example['options'] if opt != example['gt']]\n",
    "            if wrong_options:\n",
    "                random.seed(42 + idx)\n",
    "                wrong_answer = random.choice(wrong_options)\n",
    "            else:\n",
    "                wrong_answer = \"wrong answer\"\n",
    "            example['washed_output'] = f\"{example['input']}The wrong answer is {wrong_answer}\"\n",
    "            return example\n",
    "    \n",
    "        dst_pos = train_dst.map(get_pos_example, new_fingerprint=str(time()))\n",
    "        dst_neg = train_dst.map(get_neg_example, with_indices=True, new_fingerprint=str(time()))\n",
    "        return dst_pos, dst_neg\n",
    "    \n",
    "    func_map = {\n",
    "        'allenai/sciq': get_paired_dst_sciq,\n",
    "        'stanfordnlp/coqa': get_paired_dst_coqa,\n",
    "        'lucadiliello/triviaqa': get_paired_dst_triviaqa,\n",
    "        'openlifescienceai/medmcqa': get_paired_dst_medmcqa,\n",
    "        'GBaker/MedQA-USMLE-4-options': get_paired_dst_medmcqa\n",
    "    }\n",
    "    func = func_map[dst_name]\n",
    "    dst_pos, dst_neg = func(train_dst)\n",
    "    \n",
    "    data_pos = dst_pos['washed_output']\n",
    "    data_neg = dst_neg['washed_output']\n",
    "    data_size = len(data_pos)\n",
    "    full_act_names = [utils.get_act_name(act_name, l) for l in sorted(layers)]\n",
    "    v_c = torch.zeros((len(layers), 1, model.cfg.d_model)).cuda()\n",
    "\n",
    "    for i in tqdm(range(0, data_size, batch_size)):\n",
    "        batch_pos = data_pos[i:i + batch_size]\n",
    "        batch_neg = data_neg[i:i + batch_size]\n",
    "\n",
    "        _, cache_pos = model.run_with_cache(batch_pos, names_filter=lambda x: x in full_act_names, padding_side='left')  # logits: (bsz pos vocab) cache: dict\n",
    "        _, cache_neg = model.run_with_cache(batch_neg, names_filter=lambda x: x in full_act_names, padding_side='left')  # logits: (bsz pos vocab) cache: dict\n",
    "\n",
    "        cache_pos = einops.rearrange([cache_pos[name] for name in full_act_names], 'l b p d -> b l p d')\n",
    "        cache_neg = einops.rearrange([cache_neg[name] for name in full_act_names], 'l b p d -> b l p d')\n",
    "\n",
    "        cache_pos = cache_pos[:, :, [-1], :]\n",
    "        cache_neg = cache_neg[:, :, [-1], :]\n",
    "\n",
    "        v_c += (cache_pos.sum(dim=0) - cache_neg.sum(dim=0))\n",
    "\n",
    "    v_c /= data_size\n",
    "\n",
    "    v_c = v_c.cpu().float()\n",
    "    v_c = F.normalize(v_c, p=2, dim=-1)\n",
    "    return v_c\n",
    "\n",
    "\n",
    "# clean_exp exp\n",
    "def clean_exp(dst, v_c, layers, act_name):\n",
    "    fig = go.Figure()\n",
    "    c_scores = []\n",
    "    w_scores = []\n",
    "    labels = []\n",
    "    u_scores = []\n",
    "    u_scores_z = []\n",
    "    all_pe_u_scores = []\n",
    "    all_ln_pe_u_scores = []\n",
    "\n",
    "    def batch_get_result(examples):\n",
    "        all_outputs = []\n",
    "        all_num_answer_tokens = []\n",
    "        all_num_input_tokens = list(map(len, model.to_str_tokens(examples['input'])))\n",
    "        bsz = len(examples['input'])\n",
    "\n",
    "        for i in range(bsz):\n",
    "            example = {k: examples[k][i] for k in examples.keys()}\n",
    "            if example.get(\"options\"):\n",
    "                wrong_options = [opt for opt in example['options']]\n",
    "                for opt in wrong_options:\n",
    "                    if opt == example['gt']:\n",
    "                        wrong_options.remove(opt)\n",
    "                        break\n",
    "            elif example.get(\"answers\"):\n",
    "                wrong_options = [opt for opt in example['answers']['input_text']]\n",
    "                for opt in wrong_options:\n",
    "                    if opt == example['gt']:\n",
    "                        wrong_options.remove(opt)\n",
    "                        break\n",
    "                wrong_options = wrong_options[:3]\n",
    "            else:\n",
    "                wrong_options = ['wrong answer', 'bad answer', 'incorrect answer']\n",
    "            correct_output = example['input'] + example['gt']\n",
    "            wrong_outputs = [example['input'] + opt for opt in wrong_options]\n",
    "            all_outputs.extend([correct_output] + wrong_outputs)\n",
    "            num_answer_tokens = list(map(len, model.to_str_tokens([example['gt']] + wrong_options)))\n",
    "            all_num_answer_tokens.append(num_answer_tokens)\n",
    "\n",
    "        full_act_names = [utils.get_act_name(act_name, l) for l in sorted(layers)]\n",
    "\n",
    "        batch_logits, batch_cache = model.run_with_cache(all_outputs, names_filter=lambda x: x in full_act_names,\n",
    "                                                         device='cpu',\n",
    "                                                         padding_side='left')  # logits: (bsz pos vocab) cache: dict\n",
    "        batch_cache = einops.rearrange([batch_cache[name] for name in full_act_names],\n",
    "                                       'l b p d -> b l p d').float().cpu()\n",
    "        batch_cache = einops.rearrange(batch_cache, '(b o) l p d -> b o l p d', o=4)\n",
    "        batch_cache = batch_cache[:, :, :, [-1], :]\n",
    "\n",
    "        batch_logits = batch_logits.cpu().float()\n",
    "        batch_logits = einops.rearrange(batch_logits, '(b o) p v -> b o p v', o=4)\n",
    "\n",
    "        for i, lg_4 in enumerate(batch_logits):\n",
    "            num_answer_tokens = all_num_answer_tokens[i]\n",
    "            num_input_tokens = all_num_input_tokens[i]\n",
    "            for j, lg in enumerate(lg_4):\n",
    "                output = all_outputs[i * 4 + j]\n",
    "                answer_lg = lg[-num_answer_tokens[j] - 1:-1]\n",
    "                answer_prob = F.softmax(answer_lg, dim=-1)\n",
    "                answer_target_prob = answer_prob.max(dim=-1).values\n",
    "                pe = -torch.log(answer_target_prob).sum().item()\n",
    "                # print(f\"pe:{pe}\")\n",
    "                ln_pe = -torch.log(answer_target_prob).mean().item()\n",
    "                # print(f\"ln_pe:{ln_pe}\")\n",
    "                all_pe_u_scores.append(pe)\n",
    "                all_ln_pe_u_scores.append(ln_pe)\n",
    "\n",
    "        batch_in_vivo_auroc = []\n",
    "        for i in range(bsz):\n",
    "            cache = batch_cache[i]\n",
    "            u_score = einsum('b l p d, l p d -> b', cache, v_c)\n",
    "            u_score_z = (u_score - u_score.mean()) / u_score.std()\n",
    "\n",
    "            u_score = u_score.tolist()\n",
    "            u_score_z = u_score_z.tolist()\n",
    "\n",
    "            in_vivo_auroc = roc_auc_score([1, 0, 0, 0], u_score)\n",
    "            batch_in_vivo_auroc.append(in_vivo_auroc)\n",
    "            # if u_score[0] > max(u_score[1:]):\n",
    "            #     batch_in_vivo_auroc.append(1)\n",
    "            # else:\n",
    "            #     batch_in_vivo_auroc.append(0)\n",
    "\n",
    "            c_scores.append(u_score_z[0])\n",
    "            w_scores.extend(u_score_z[1:])\n",
    "            labels.extend([1, 0, 0, 0])\n",
    "\n",
    "            # assert len(u_score) == 4, f\"{len(u_score)} {example['options']}\"\n",
    "            u_scores.extend(u_score)\n",
    "            u_scores_z.extend(u_score_z)\n",
    "\n",
    "        examples['in_vivo_auroc'] = batch_in_vivo_auroc\n",
    "        return examples\n",
    "\n",
    "    new_dst = dst.map(batch_get_result, new_fingerprint=str(time()), batched=True, batch_size=4)\n",
    "\n",
    "    in_vivo_auroc = sum(new_dst['in_vivo_auroc']) / len(new_dst['in_vivo_auroc'])\n",
    "    flag = in_vivo_auroc > 0.5\n",
    "    in_vivo_auroc = in_vivo_auroc if flag else 1 - in_vivo_auroc\n",
    "    print(f\"in-vivo u_score auroc: {in_vivo_auroc}\")\n",
    "\n",
    "    in_vitro_auroc = roc_auc_score(labels, u_scores)\n",
    "    in_vitro_auroc = in_vitro_auroc if flag else 1 - in_vitro_auroc\n",
    "    print(f\"in-vitro u_score auroc: {in_vitro_auroc}\")\n",
    "\n",
    "    in_vitro_auroc_z = roc_auc_score(labels, u_scores_z)\n",
    "    in_vitro_auroc_z = in_vitro_auroc_z if flag else 1 - in_vitro_auroc_z\n",
    "    print(f\"in-vitro u_score_z auroc: {in_vitro_auroc_z}\")\n",
    "\n",
    "    in_vitro_pe_auroc = roc_auc_score(labels, all_pe_u_scores)\n",
    "    print(f\"in-vitro pe auroc: {in_vitro_pe_auroc}\")\n",
    "\n",
    "    in_vitro_ln_pe_auroc = roc_auc_score(labels, all_ln_pe_u_scores)\n",
    "    print(f\"in-vitro ln_pe auroc: {in_vitro_ln_pe_auroc}\")\n",
    "\n",
    "    fig.add_trace(go.Histogram(x=c_scores, name='Correct', opacity=0.5, nbinsx=100))\n",
    "    fig.add_trace(go.Histogram(x=w_scores, name='Wrong', opacity=0.5, nbinsx=100))\n",
    "    fig.update_layout(barmode='overlay')\n",
    "    fig.show()\n",
    "\n",
    "'''\n",
    "Compared Baseline Methods:\n",
    "PE(Predictive Entropy),\n",
    "LN-PE(Length-normalised Predictive Entropy),\n",
    "SAR(Shifting Attention to more Relevant),\n",
    "LS(Lexical Similarity),\n",
    "SE(Semantic Entropy),\n",
    "SR(Self-Report)\n",
    "Ours(Activation Based)\n",
    "'''\n",
    "\n",
    "# Evaluation: AUROC with Correctness Metric\n",
    "def get_auroc(val_dst, u_metric, c_metric, c_th):\n",
    "    c_metrics = val_dst[c_metric]\n",
    "    label = [1 if c > c_th else 0 for c in c_metrics]\n",
    "    u_score = val_dst[u_metric]\n",
    "    auroc = roc_auc_score(label, u_score)\n",
    "    auroc = auroc if auroc > 0.5 else 1 - auroc\n",
    "    return auroc\n",
    "\n",
    "def plot_th_curve(test_dst, u_metrics, c_metric, nbins=10):\n",
    "    fig = go.Figure()\n",
    "    th_range = [i / nbins for i in range(1, nbins)]\n",
    "    accs = []\n",
    "    c_metrics = test_dst[c_metric]\n",
    "\n",
    "    for th in th_range:\n",
    "        acc = 0\n",
    "        for c in c_metrics:\n",
    "            if c > th:\n",
    "                acc += 1\n",
    "        acc = acc / len(c_metrics)\n",
    "        accs.append(acc)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=th_range, y=accs, mode='lines+markers+text', name=f\"acc\", text=[f\"{a:.4f}\" for a in accs], textposition=\"top center\"))\n",
    "\n",
    "    for u_metric in u_metrics:\n",
    "        aurocs = []\n",
    "        for th in th_range:\n",
    "            aurocs.append(get_auroc(test_dst, u_metric, c_metric, th))\n",
    "        fig.add_trace(go.Scatter(x=th_range, y=aurocs, mode='lines+markers+text', name=f\"{u_metric}\", text=[f\"{a:.4f}\" for a in aurocs], textposition=\"top center\"))\n",
    "    fig.update_layout(title=f\"AUROC/{c_metric}-Threshold Curve\", xaxis_title=f\"{c_metric}-Threshold\", yaxis_title=\"AUROC\", width=2000, height=1000)\n",
    "    fig.write_image(f\"eval_results/{dst_name}_{model_name}_{c_metric}_th_curve.png\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e72a9129651081dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T14:31:25.812191Z",
     "start_time": "2024-03-24T14:31:25.124814Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m u_metrics \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtest_dst\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu_score\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m k\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m      3\u001b[0m fig \u001b[38;5;241m=\u001b[39m plot_th_curve(test_dst, u_metrics, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrougel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dst' is not defined"
     ]
    }
   ],
   "source": [
    "u_metrics = [k for k in test_dst[0].keys() if k.startswith(\"u_score\") and not k.endswith(\"all\")]\n",
    "fig = plot_th_curve(test_dst, u_metrics, 'rougel')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c4db69225b79de49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T15:20:35.189620Z",
     "start_time": "2024-03-21T15:20:35.065244Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4144e251dcb44eb3b510d430cac10d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt:Abnormal migration of ventral pancreatic bud\n",
      "options:['Complete failure of proximal duodenum to recanalize', 'Abnormal migration of ventral pancreatic bud', 'Abnormal hypertrophy of the pylorus', 'Failure of lateral body folds to move ventrally and fuse in the midline']\n",
      "8\n",
      "1 The most likely embryologic error that could account for this presentation is:  Abnormal migration of the ventral pancreatic bud\n",
      "2 This error occurs when the ventral pancreatic bud, which gives rise to the pancreas, migrates too far down the embryonic gut and gets stuck in the duodenum, preventing the normal flow of bile and pancreatic juices into the duodenum\n",
      "3 This can lead to regurgitation of feeds and yellow vomit due to the accumulation of bile in the stomach\n",
      "4 The child's abdominal distension and lack of other abnormalities on physical exam support this diagnosis\n",
      "5 Complete failure of proximal duodenum to recanalize and abnormal hypertrophy of the pylorus are less likely explanations for this presentation\n",
      "6 Failure of lateral body folds to move ventrally and fuse in the midline is not a known embryologic error\n",
      "7 \n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208
         ],
         "xaxis": "x",
         "y": [
          1.2078866958618164,
          0.8817383646965027,
          0.003913899417966604,
          0.05211600288748741,
          0,
          0,
          0,
          0,
          0.003913899417966604,
          0,
          0,
          0,
          0.47627323865890503,
          0,
          0.003913899417966604,
          1.5378443002700806,
          0.2929040193557739,
          0.15154990553855896,
          0.2221674621105194,
          0,
          0.5278975963592529,
          0,
          0.6325225830078125,
          0,
          0,
          0,
          0,
          0,
          0,
          0.4392319619655609,
          0.007843177765607834,
          0,
          0.06038051098585129,
          0.8089789748191833,
          0.603534996509552,
          0.01574835740029812,
          0,
          0.37469345331192017,
          0,
          0,
          0,
          0,
          0,
          0.910448431968689,
          0.003913899417966604,
          0.15610571205615997,
          0,
          0,
          0,
          0.4271836280822754,
          0,
          0.04800922051072121,
          0.007843177765607834,
          0.7248958945274353,
          0,
          0.5684437155723572,
          0.14701473712921143,
          0.7289363145828247,
          0.01972450502216816,
          0.16989903151988983,
          0,
          0.16068238019943237,
          0.10709813237190247,
          0.6473376154899597,
          0.7618610858917236,
          0.25187262892723083,
          0.7618610858917236,
          0.011787955649197102,
          0.6179237365722656,
          0,
          0.01972450502216816,
          0.0941389873623848,
          0.817789614200592,
          0,
          0.28768208622932434,
          0.37469345331192017,
          0.9551209211349487,
          0,
          0.39768296480178833,
          0.007843177765607834,
          0.01574835740029812,
          0.07711730152368546,
          0,
          0,
          0.4700036346912384,
          0.47627323865890503,
          0.027724547311663628,
          0,
          0.04391923546791077,
          0,
          0,
          0.07290676981210709,
          0.03578910604119301,
          0.03578910604119301,
          0.33569130301475525,
          0,
          1.4718862771987915,
          0,
          0,
          0.369027704000473,
          0.21730127930641174,
          0,
          0.5823327898979187,
          0.6179237365722656,
          1.138458251953125,
          0.003913899417966604,
          0.5479651689529419,
          0,
          0.4453110098838806,
          1.275480031967163,
          0,
          0,
          0.11583181470632553,
          0.007843177765607834,
          0.027724547311663628,
          0,
          0.06871389597654343,
          0,
          0,
          0.03578910604119301,
          0.7088955640792847,
          0.4453110098838806,
          0.11583181470632553,
          0,
          0.4889316260814667,
          0.5823327898979187,
          0,
          0.01972450502216816,
          0.3861221373081207,
          0.31943076848983765,
          0.6473376154899597,
          0,
          0.16528008878231049,
          0.011787955649197102,
          0,
          0.07290676981210709,
          0.007843177765607834,
          0.06871389597654343,
          0,
          0.37469345331192017,
          0.011787955649197102,
          0.011787955649197102,
          0,
          0.01574835740029812,
          0.5147395133972168,
          0,
          1.007215976715088,
          0,
          0,
          0.07711730152368546,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0.6623755097389221,
          0.003913899417966604,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0.003913899417966604,
          0.08134564012289047,
          0,
          1.3330498933792114,
          0,
          0.5547448396682739,
          0.4271836280822754,
          0.007843177765607834,
          0.4700036346912384,
          0.3803914785385132,
          0,
          0,
          0.003913899417966604,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0.04391923546791077,
          0.8222241997718811,
          0.9350197315216064,
          1.034317970275879,
          0.003913899417966604,
          0,
          0,
          0,
          0.003913899417966604,
          0.20763936638832092
         ],
         "yaxis": "y"
        },
        {
         "mode": "lines+markers",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208
         ],
         "xaxis": "x2",
         "y": [
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.2067117885172624,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.21949542494821211,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.2632103524935831,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1864378412331765,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.1339769039036972,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428,
          0.12325393161736428
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Token Level",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Sentence Level",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 1000,
        "margin": {
         "b": 50,
         "l": 0,
         "r": 0,
         "t": 50
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "The most likely embryologic error that could account for this presentation is:\n\nAbnormal migration of the ventral pancreatic bud.\n\nThis error occurs when the ventral pancreatic bud, which gives rise to the pancreas, migrates too far down the embryonic gut and gets stuck in the duodenum, preventing the normal flow of bile and pancreatic juices into the duodenum. This can lead to regurgitation of feeds and yellow vomit due to the accumulation of bile in the stomach. The child's abdominal distension and lack of other abnormalities on physical exam support this diagnosis.\n\nComplete failure of proximal duodenum to recanalize and abnormal hypertrophy of the pylorus are less likely explanations for this presentation. Failure of lateral body folds to move ventrally and fuse in the midline is not a known embryologic error."
        },
        "width": 2500,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "ticktext": [
          "The",
          "most",
          "likely",
          "emb",
          "ry",
          "olog",
          "ic",
          "error",
          "that",
          "could",
          "account",
          "for",
          "this",
          "presentation",
          "is",
          ":",
          "\n",
          "\n",
          "Ab",
          "normal",
          "migration",
          "of",
          "the",
          "vent",
          "ral",
          "pan",
          "cre",
          "atic",
          "bud",
          ".",
          "\n",
          "\n",
          "This",
          "error",
          "occurs",
          "when",
          "the",
          "vent",
          "ral",
          "pan",
          "cre",
          "atic",
          "bud",
          ",",
          "which",
          "gives",
          "rise",
          "to",
          "the",
          "pan",
          "cre",
          "as",
          ",",
          "migr",
          "ates",
          "too",
          "far",
          "down",
          "the",
          "emb",
          "ry",
          "onic",
          "gut",
          "and",
          "gets",
          "stuck",
          "in",
          "the",
          "du",
          "oden",
          "um",
          ",",
          "prevent",
          "ing",
          "the",
          "normal",
          "flow",
          "of",
          "b",
          "ile",
          "and",
          "pan",
          "cre",
          "atic",
          "ju",
          "ices",
          "into",
          "the",
          "du",
          "oden",
          "um",
          ".",
          "This",
          "can",
          "lead",
          "to",
          "reg",
          "urg",
          "itation",
          "of",
          "fe",
          "eds",
          "and",
          "yellow",
          "vom",
          "it",
          "due",
          "to",
          "the",
          "accum",
          "ulation",
          "of",
          "b",
          "ile",
          "in",
          "the",
          "st",
          "om",
          "ach",
          ".",
          "The",
          "child",
          "'",
          "s",
          "ab",
          "dom",
          "inal",
          "dist",
          "ension",
          "and",
          "lack",
          "of",
          "other",
          "ab",
          "normal",
          "ities",
          "on",
          "physical",
          "exam",
          "support",
          "this",
          "diagn",
          "osis",
          ".",
          "\n",
          "\n",
          "Complete",
          "failure",
          "of",
          "proxim",
          "al",
          "du",
          "oden",
          "um",
          "to",
          "rec",
          "anal",
          "ize",
          "and",
          "ab",
          "normal",
          "hy",
          "pert",
          "ro",
          "phy",
          "of",
          "the",
          "p",
          "yl",
          "orus",
          "are",
          "less",
          "likely",
          "explan",
          "ations",
          "for",
          "this",
          "presentation",
          ".",
          "Fail",
          "ure",
          "of",
          "later",
          "al",
          "body",
          "fol",
          "ds",
          "to",
          "move",
          "vent",
          "r",
          "ally",
          "and",
          "f",
          "use",
          "in",
          "the",
          "mid",
          "line",
          "is",
          "not",
          "a",
          "known",
          "emb",
          "ry",
          "olog",
          "ic",
          "error",
          "."
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208
         ],
         "title": {
          "text": "Token"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          1
         ],
         "ticktext": [
          "The",
          "most",
          "likely",
          "emb",
          "ry",
          "olog",
          "ic",
          "error",
          "that",
          "could",
          "account",
          "for",
          "this",
          "presentation",
          "is",
          ":",
          "\n",
          "\n",
          "Ab",
          "normal",
          "migration",
          "of",
          "the",
          "vent",
          "ral",
          "pan",
          "cre",
          "atic",
          "bud",
          ".",
          "\n",
          "\n",
          "This",
          "error",
          "occurs",
          "when",
          "the",
          "vent",
          "ral",
          "pan",
          "cre",
          "atic",
          "bud",
          ",",
          "which",
          "gives",
          "rise",
          "to",
          "the",
          "pan",
          "cre",
          "as",
          ",",
          "migr",
          "ates",
          "too",
          "far",
          "down",
          "the",
          "emb",
          "ry",
          "onic",
          "gut",
          "and",
          "gets",
          "stuck",
          "in",
          "the",
          "du",
          "oden",
          "um",
          ",",
          "prevent",
          "ing",
          "the",
          "normal",
          "flow",
          "of",
          "b",
          "ile",
          "and",
          "pan",
          "cre",
          "atic",
          "ju",
          "ices",
          "into",
          "the",
          "du",
          "oden",
          "um",
          ".",
          "This",
          "can",
          "lead",
          "to",
          "reg",
          "urg",
          "itation",
          "of",
          "fe",
          "eds",
          "and",
          "yellow",
          "vom",
          "it",
          "due",
          "to",
          "the",
          "accum",
          "ulation",
          "of",
          "b",
          "ile",
          "in",
          "the",
          "st",
          "om",
          "ach",
          ".",
          "The",
          "child",
          "'",
          "s",
          "ab",
          "dom",
          "inal",
          "dist",
          "ension",
          "and",
          "lack",
          "of",
          "other",
          "ab",
          "normal",
          "ities",
          "on",
          "physical",
          "exam",
          "support",
          "this",
          "diagn",
          "osis",
          ".",
          "\n",
          "\n",
          "Complete",
          "failure",
          "of",
          "proxim",
          "al",
          "du",
          "oden",
          "um",
          "to",
          "rec",
          "anal",
          "ize",
          "and",
          "ab",
          "normal",
          "hy",
          "pert",
          "ro",
          "phy",
          "of",
          "the",
          "p",
          "yl",
          "orus",
          "are",
          "less",
          "likely",
          "explan",
          "ations",
          "for",
          "this",
          "presentation",
          ".",
          "Fail",
          "ure",
          "of",
          "later",
          "al",
          "body",
          "fol",
          "ds",
          "to",
          "move",
          "vent",
          "r",
          "ally",
          "and",
          "f",
          "use",
          "in",
          "the",
          "mid",
          "line",
          "is",
          "not",
          "a",
          "known",
          "emb",
          "ry",
          "olog",
          "ic",
          "error",
          "."
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208
         ],
         "title": {
          "text": "Sentence"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          0.375
         ]
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"ac7242a1-35e4-4297-bad0-e7caa037c194\" class=\"plotly-graph-div\" style=\"height:1000px; width:2500px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ac7242a1-35e4-4297-bad0-e7caa037c194\")) {                    Plotly.newPlot(                        \"ac7242a1-35e4-4297-bad0-e7caa037c194\",                        [{\"mode\":\"lines+markers\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208],\"y\":[1.2078866958618164,0.8817383646965027,0.003913899417966604,0.05211600288748741,-0.0,-0.0,-0.0,-0.0,0.003913899417966604,-0.0,-0.0,-0.0,0.47627323865890503,-0.0,0.003913899417966604,1.5378443002700806,0.2929040193557739,0.15154990553855896,0.2221674621105194,-0.0,0.5278975963592529,-0.0,0.6325225830078125,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,0.4392319619655609,0.007843177765607834,-0.0,0.06038051098585129,0.8089789748191833,0.603534996509552,0.01574835740029812,-0.0,0.37469345331192017,-0.0,-0.0,-0.0,-0.0,-0.0,0.910448431968689,0.003913899417966604,0.15610571205615997,-0.0,-0.0,-0.0,0.4271836280822754,-0.0,0.04800922051072121,0.007843177765607834,0.7248958945274353,-0.0,0.5684437155723572,0.14701473712921143,0.7289363145828247,0.01972450502216816,0.16989903151988983,-0.0,0.16068238019943237,0.10709813237190247,0.6473376154899597,0.7618610858917236,0.25187262892723083,0.7618610858917236,0.011787955649197102,0.6179237365722656,-0.0,0.01972450502216816,0.0941389873623848,0.817789614200592,-0.0,0.28768208622932434,0.37469345331192017,0.9551209211349487,-0.0,0.39768296480178833,0.007843177765607834,0.01574835740029812,0.07711730152368546,-0.0,-0.0,0.4700036346912384,0.47627323865890503,0.027724547311663628,-0.0,0.04391923546791077,-0.0,-0.0,0.07290676981210709,0.03578910604119301,0.03578910604119301,0.33569130301475525,-0.0,1.4718862771987915,-0.0,-0.0,0.369027704000473,0.21730127930641174,-0.0,0.5823327898979187,0.6179237365722656,1.138458251953125,0.003913899417966604,0.5479651689529419,-0.0,0.4453110098838806,1.275480031967163,-0.0,-0.0,0.11583181470632553,0.007843177765607834,0.027724547311663628,-0.0,0.06871389597654343,-0.0,-0.0,0.03578910604119301,0.7088955640792847,0.4453110098838806,0.11583181470632553,-0.0,0.4889316260814667,0.5823327898979187,-0.0,0.01972450502216816,0.3861221373081207,0.31943076848983765,0.6473376154899597,-0.0,0.16528008878231049,0.011787955649197102,-0.0,0.07290676981210709,0.007843177765607834,0.06871389597654343,-0.0,0.37469345331192017,0.011787955649197102,0.011787955649197102,-0.0,0.01574835740029812,0.5147395133972168,-0.0,1.007215976715088,-0.0,-0.0,0.07711730152368546,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,0.6623755097389221,0.003913899417966604,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,0.003913899417966604,0.08134564012289047,-0.0,1.3330498933792114,-0.0,0.5547448396682739,0.4271836280822754,0.007843177765607834,0.4700036346912384,0.3803914785385132,-0.0,-0.0,0.003913899417966604,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,-0.0,0.04391923546791077,0.8222241997718811,0.9350197315216064,1.034317970275879,0.003913899417966604,-0.0,-0.0,-0.0,0.003913899417966604,0.20763936638832092],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines+markers\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208],\"y\":[0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.2067117885172624,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.21949542494821211,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.2632103524935831,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1864378412331765,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.1339769039036972,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428,0.12325393161736428],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Token\"},\"tickvals\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208],\"ticktext\":[\"The\",\"most\",\"likely\",\"emb\",\"ry\",\"olog\",\"ic\",\"error\",\"that\",\"could\",\"account\",\"for\",\"this\",\"presentation\",\"is\",\":\",\"\\n\",\"\\n\",\"Ab\",\"normal\",\"migration\",\"of\",\"the\",\"vent\",\"ral\",\"pan\",\"cre\",\"atic\",\"bud\",\".\",\"\\n\",\"\\n\",\"This\",\"error\",\"occurs\",\"when\",\"the\",\"vent\",\"ral\",\"pan\",\"cre\",\"atic\",\"bud\",\",\",\"which\",\"gives\",\"rise\",\"to\",\"the\",\"pan\",\"cre\",\"as\",\",\",\"migr\",\"ates\",\"too\",\"far\",\"down\",\"the\",\"emb\",\"ry\",\"onic\",\"gut\",\"and\",\"gets\",\"stuck\",\"in\",\"the\",\"du\",\"oden\",\"um\",\",\",\"prevent\",\"ing\",\"the\",\"normal\",\"flow\",\"of\",\"b\",\"ile\",\"and\",\"pan\",\"cre\",\"atic\",\"ju\",\"ices\",\"into\",\"the\",\"du\",\"oden\",\"um\",\".\",\"This\",\"can\",\"lead\",\"to\",\"reg\",\"urg\",\"itation\",\"of\",\"fe\",\"eds\",\"and\",\"yellow\",\"vom\",\"it\",\"due\",\"to\",\"the\",\"accum\",\"ulation\",\"of\",\"b\",\"ile\",\"in\",\"the\",\"st\",\"om\",\"ach\",\".\",\"The\",\"child\",\"'\",\"s\",\"ab\",\"dom\",\"inal\",\"dist\",\"ension\",\"and\",\"lack\",\"of\",\"other\",\"ab\",\"normal\",\"ities\",\"on\",\"physical\",\"exam\",\"support\",\"this\",\"diagn\",\"osis\",\".\",\"\\n\",\"\\n\",\"Complete\",\"failure\",\"of\",\"proxim\",\"al\",\"du\",\"oden\",\"um\",\"to\",\"rec\",\"anal\",\"ize\",\"and\",\"ab\",\"normal\",\"hy\",\"pert\",\"ro\",\"phy\",\"of\",\"the\",\"p\",\"yl\",\"orus\",\"are\",\"less\",\"likely\",\"explan\",\"ations\",\"for\",\"this\",\"presentation\",\".\",\"Fail\",\"ure\",\"of\",\"later\",\"al\",\"body\",\"fol\",\"ds\",\"to\",\"move\",\"vent\",\"r\",\"ally\",\"and\",\"f\",\"use\",\"in\",\"the\",\"mid\",\"line\",\"is\",\"not\",\"a\",\"known\",\"emb\",\"ry\",\"olog\",\"ic\",\"error\",\".\"]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Sentence\"},\"tickvals\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208],\"ticktext\":[\"The\",\"most\",\"likely\",\"emb\",\"ry\",\"olog\",\"ic\",\"error\",\"that\",\"could\",\"account\",\"for\",\"this\",\"presentation\",\"is\",\":\",\"\\n\",\"\\n\",\"Ab\",\"normal\",\"migration\",\"of\",\"the\",\"vent\",\"ral\",\"pan\",\"cre\",\"atic\",\"bud\",\".\",\"\\n\",\"\\n\",\"This\",\"error\",\"occurs\",\"when\",\"the\",\"vent\",\"ral\",\"pan\",\"cre\",\"atic\",\"bud\",\",\",\"which\",\"gives\",\"rise\",\"to\",\"the\",\"pan\",\"cre\",\"as\",\",\",\"migr\",\"ates\",\"too\",\"far\",\"down\",\"the\",\"emb\",\"ry\",\"onic\",\"gut\",\"and\",\"gets\",\"stuck\",\"in\",\"the\",\"du\",\"oden\",\"um\",\",\",\"prevent\",\"ing\",\"the\",\"normal\",\"flow\",\"of\",\"b\",\"ile\",\"and\",\"pan\",\"cre\",\"atic\",\"ju\",\"ices\",\"into\",\"the\",\"du\",\"oden\",\"um\",\".\",\"This\",\"can\",\"lead\",\"to\",\"reg\",\"urg\",\"itation\",\"of\",\"fe\",\"eds\",\"and\",\"yellow\",\"vom\",\"it\",\"due\",\"to\",\"the\",\"accum\",\"ulation\",\"of\",\"b\",\"ile\",\"in\",\"the\",\"st\",\"om\",\"ach\",\".\",\"The\",\"child\",\"'\",\"s\",\"ab\",\"dom\",\"inal\",\"dist\",\"ension\",\"and\",\"lack\",\"of\",\"other\",\"ab\",\"normal\",\"ities\",\"on\",\"physical\",\"exam\",\"support\",\"this\",\"diagn\",\"osis\",\".\",\"\\n\",\"\\n\",\"Complete\",\"failure\",\"of\",\"proxim\",\"al\",\"du\",\"oden\",\"um\",\"to\",\"rec\",\"anal\",\"ize\",\"and\",\"ab\",\"normal\",\"hy\",\"pert\",\"ro\",\"phy\",\"of\",\"the\",\"p\",\"yl\",\"orus\",\"are\",\"less\",\"likely\",\"explan\",\"ations\",\"for\",\"this\",\"presentation\",\".\",\"Fail\",\"ure\",\"of\",\"later\",\"al\",\"body\",\"fol\",\"ds\",\"to\",\"move\",\"vent\",\"r\",\"ally\",\"and\",\"f\",\"use\",\"in\",\"the\",\"mid\",\"line\",\"is\",\"not\",\"a\",\"known\",\"emb\",\"ry\",\"olog\",\"ic\",\"error\",\".\"]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Token Level\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Sentence Level\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"margin\":{\"l\":0,\"r\":0,\"b\":50,\"t\":50},\"title\":{\"text\":\"The most likely embryologic error that could account for this presentation is:\\n\\nAbnormal migration of the ventral pancreatic bud.\\n\\nThis error occurs when the ventral pancreatic bud, which gives rise to the pancreas, migrates too far down the embryonic gut and gets stuck in the duodenum, preventing the normal flow of bile and pancreatic juices into the duodenum. This can lead to regurgitation of feeds and yellow vomit due to the accumulation of bile in the stomach. The child's abdominal distension and lack of other abnormalities on physical exam support this diagnosis.\\n\\nComplete failure of proximal duodenum to recanalize and abnormal hypertrophy of the pylorus are less likely explanations for this presentation. Failure of lateral body folds to move ventrally and fuse in the midline is not a known embryologic error.\"},\"height\":1000,\"width\":2500},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('ac7242a1-35e4-4297-bad0-e7caa037c194');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = test_dst.filter(lambda x: x['rougel'] <0.1)[1]\n",
    "example = test_dst[2]\n",
    "print(f\"gt:{example['gt']}\")\n",
    "print(f\"options:{example['options']}\")\n",
    "\n",
    "str_tokens = model.to_str_tokens(f\":{example['washed_answer']}\", prepend_bos=False)[1:]\n",
    "fig = make_subplots(rows=2, cols=1, subplot_titles=(\"Token Level\", \"Sentence Level\"), row_heights=[0.5, 0.5])\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(range(len(str_tokens))), y=example['u_score_pe_all'], mode='lines+markers'), row=1, col=1)\n",
    "fig.update_xaxes(title_text='Token', tickvals=list(range(len(str_tokens))), ticktext=str_tokens, row=1, col=1)\n",
    "\n",
    "sentence_u_score_pe_all = []\n",
    "indices = [0]+[i for i, x in enumerate(str_tokens) if x == '.']+[-1]\n",
    "spans = [(indices[i], indices[i+1]) for i in range(len(indices)-1)]\n",
    "print(len(indices))\n",
    "for span in spans:\n",
    "    sentence_score = sum(example['u_score_pe_all'][span[0]:span[1]]) / (span[1] - span[0])\n",
    "    sentence_u_score_pe_all.extend([sentence_score] * (span[1] - span[0]))\n",
    "sentence_u_score_pe_all.append(sentence_u_score_pe_all[-1])\n",
    "# print(str_tokens)\n",
    "for i, sentence in enumerate(example['washed_answer'].split(\".\")):\n",
    "    print(i+1,sentence.replace(\"\\n\",' ').strip())\n",
    "# print(len(example['u_score_pe_all']))\n",
    "# print(sentence_u_score_pe_all)\n",
    "# print(len(sentence_u_score_pe_all))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(range(len(str_tokens))), y=sentence_u_score_pe_all, mode='lines+markers'), row=2, col=1)\n",
    "fig.update_xaxes(title_text='Sentence', tickvals=list(range(len(str_tokens))), ticktext=str_tokens, row=2, col=1)\n",
    "\n",
    "fig.update_layout(height=1000, width=2500, margin=dict(l=0, r=0, b=50, t=50), title_text=example['washed_answer'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed57a4803dbff5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
