{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3ad78fe71283d0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Inplementation of Internal State-based Uncertainty Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b278c24516568ba0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. 数据集预处理：将不同格式的数据集处理成input+gt的格式，方便判断模型的correctness，这一部分的采用固定不可调整的prompt，即Context: Question: Options: Answer:格式\n",
    "2. 生成回复，为每个模型确定一个prompt，一个max_new_tokens数，然后生成回复\n",
    "3. 计算回复部分的correctness指标，判断模型的回复是否正确\n",
    "4. 计算uncertainty指标，包括PE, LN-PE, SAR, Ours\n",
    "5. 计算AUROC，绘制AUROC/Correctness-Threshold曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:15:09.457816Z",
     "start_time": "2024-04-08T12:14:50.494726Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "datasets.disable_caching()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Eval Result Config\n",
    "model_names = [\n",
    "    \"vicuna-7b-v1.1\",\n",
    "    \"vicuna-13b-v1.1\",\n",
    "    \"vicuna-33b-v1.3\",\n",
    "]\n",
    "\n",
    "dst_names = [\n",
    "    \"sciq\",\n",
    "    \"coqa\",\n",
    "    \"triviaqa\",\n",
    "    \"medmcqa\",\n",
    "    \"MedQA-USMLE-4-options\",\n",
    "]\n",
    "\n",
    "c_metrics = [\n",
    "    'rougel',\n",
    "    'sentsim',\n",
    "    'include'\n",
    "]\n",
    "\n",
    "dst_types = [\n",
    "    \"short\",\n",
    "    \"long\",\n",
    "]\n",
    "\n",
    "acc_map = {\n",
    "    \"vicuna-7b-v1.1\": {\n",
    "        \"sciq\": 0.60,\n",
    "        \"coqa\": 0.8,\n",
    "        \"triviaqa\": 0.55,\n",
    "        \"medmcqa\": 0.30,\n",
    "        \"MedQA-USMLE-4-options\": 0.30\n",
    "    },\n",
    "    \"vicuna-13b-v1.1\": {\n",
    "        \"sciq\": 0.0,\n",
    "        \"coqa\": 0.0,\n",
    "        \"triviaqa\": 0.0,\n",
    "        \"medmcqa\": 0.0,\n",
    "        \"MedQA-USMLE-4-options\": 0.0\n",
    "    },\n",
    "    \"vicuna-33b-v1.3\": {\n",
    "        \"sciq\": 0.0,\n",
    "        \"coqa\": 0.0,\n",
    "        \"triviaqa\": 0.0,\n",
    "        \"medmcqa\": 0.0,\n",
    "        \"MedQA-USMLE-4-options\": 0.0\n",
    "    }\n",
    "}\n",
    "\n",
    "model_names_alias = {\n",
    "    \"vicuna-7b-v1.1\": \"Vicuna-7B\",\n",
    "    \"vicuna-13b-v1.1\": \"Vicuna-13B\",\n",
    "    \"vicuna-33b-v1.3\": \"Vicuna-33B\"\n",
    "}\n",
    "\n",
    "dst_names_alias = {\n",
    "    \"sciq\": \"SciQ\",\n",
    "    \"coqa\": \"CoQA\",\n",
    "    \"triviaqa\": \"TriviaQA\",\n",
    "    \"medmcqa\": \"MedMCQA\",\n",
    "    \"MedQA-USMLE-4-options\": \"MedQA\"\n",
    "}\n",
    "\n",
    "u_metric_alias = {\n",
    "    \"u_score_pe\": \"PE\",\n",
    "    \"u_score_ln_pe\": \"LN-PE\",\n",
    "    \"u_score_token_sar\": \"TokenSAR\",\n",
    "    \"u_score_sent_sar\": \"SentSAR\",\n",
    "    \"u_score_sar\": \"SAR\",\n",
    "    \"u_score_ls\": \"LS\",\n",
    "    \"u_score_se\": \"SE\",\n",
    "    \"u_score_ours_mean_soft_rougel\": \"Ours(MSRL)\",\n",
    "    \"u_score_ours_last_soft_rougel\": \"Ours(LSRL)\",\n",
    "    \"u_score_ours_mean_soft_include\": \"Ours(MSIN)\",\n",
    "    \"u_score_ours_last_soft_include\": \"Ours(LSIN)\",\n",
    "    \"u_score_ours_mean_soft_sentsim\": \"Ours(MSSI)\",\n",
    "    \"u_score_ours_last_soft_sentsim\": \"Ours(LSSI)\"\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "def get_cached_result_path(model_name, dst_name, dst_type, dst_split):\n",
    "    return f\"cached_results/{model_name}/{dst_type}/{dst_name}_{dst_split}\"\n",
    "\n",
    "\n",
    "def get_eval_main_result_path(model_name, dst_name, dst_type):\n",
    "    return f\"eval_results/{model_name}/{dst_name}_{dst_type}\"\n",
    "\n",
    "\n",
    "def get_eval_cross_result_path(model_name, train_dst_name, train_dst_type, test_dst_name, test_dst_type, c_metric):\n",
    "    return f\"cross_eval_results/{model_name}/{c_metric}/v_c_{train_dst_name}_{train_dst_type}_mean_soft_best.pth/{test_dst_name}_{test_dst_type}\"\n",
    "\n",
    "\n",
    "def get_c_th_by_acc(test_dst, c_metric, acc):\n",
    "    sorted_c_scores = sorted(list(test_dst[c_metric]), reverse=True)\n",
    "    c_th = sorted_c_scores[int(len(sorted_c_scores) * acc)]\n",
    "    return c_th\n",
    "\n",
    "\n",
    "def get_acc_by_c_th(test_dst, c_metric, c_th):\n",
    "    return sum([1 if s > c_th else 0 for s in test_dst[c_metric]]) / len(test_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c273cf4cd288e17d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T07:53:38.688385Z",
     "start_time": "2024-04-07T07:53:38.609839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['question', 'distractor3', 'distractor1', 'distractor2', 'correct_answer', 'support', 'input', 'dst_template', 'options', 'gt', 'answer', 'washed_answer', 'output', 'washed_output', 'sampled_answer', 'washed_sampled_answer', 'sampled_output', 'washed_sampled_output', 'num_input_tokens', 'num_output_tokens', 'num_answer_tokens', 'answer_idxs', 'rougel', 'sentsim', 'include', 'answer_prob', 'time_fwd', 'sampled_answer_prob', 'u_score_len', 'u_score_pe_all', 'u_score_pe', 'u_score_ln_pe', 'time_pe', 'u_score_token_sar', 'time_token_sar', 'time_sent_sar', 'time_sar', 'u_score_sent_sar', 'u_score_sar', 'u_score_ls', 'time_ls', 'u_score_se', 'time_se', 'u_score_ours_mean_soft_rougel', 'time_ours_mean_soft_rougel', 'u_score_ours_last_soft_rougel', 'time_ours_last_soft_rougel', 'u_score_ours_mean_soft_include', 'time_ours_mean_soft_include', 'u_score_ours_last_soft_include', 'time_ours_last_soft_include']\n",
      "question: Who proposed the theory of evolution by natural selection?\n",
      "washed_answer: Darwin, Linnaeus, Scopes, Shaw\n",
      "input: Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:\n",
      "output: Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin, Linnaeus, Scopes, Shaw</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
      "gt: darwin\n",
      "u_score_pe: 4.906757354736328\n",
      "\n",
      "question: Each specific polypeptide has a unique linear sequence of which acids?\n",
      "washed_answer: hydrochloric, amino, lactic, fatty\n",
      "input: Question:Each specific polypeptide has a unique linear sequence of which acids? Options:hydrochloric, amino, lactic, fatty Answer:\n",
      "output: Question:Each specific polypeptide has a unique linear sequence of which acids? Options:hydrochloric, amino, lactic, fatty Answer:hydrochloric, amino, lactic, fatty\n",
      "\n",
      "Question:What is the function of the enzyme pepsin in the digestive system? Options:to break down proteins into smaller peptides, to break down carbohydrates into smaller sugars, to break down fats into smaller fatty acids, to break down nucleic acids into smaller nucleotides Answer:to break down proteins into smaller peptides\n",
      "\n",
      "Question:What is the function of the enzyme trypsin in the digestive system? Options:to break down\n",
      "gt: amino\n",
      "u_score_pe: 1.8450627326965332\n",
      "\n",
      "question: A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence?\n",
      "washed_answer: genes\n",
      "input: Question:A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? Options:carotenoids, proteins, genes, nucleotides Answer:\n",
      "output: Question:A frameshift mutation is a deletion or insertion of one or more of what that changes the reading frame of the base sequence? Options:carotenoids, proteins, genes, nucleotides Answer:genes\n",
      "\n",
      "Question:A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence? Options:carotenoids, proteins, genes, nucleotides Answer:genes\n",
      "\n",
      "Question:A frameshift mutation is a deletion or insertion of one or more nucleotides that changes the reading frame of the base sequence? Options:carotenoids, proteins, genes, nucleotides Answer:genes\n",
      "\n",
      "Question:A frameshift mutation is a deletion or insertion of\n",
      "gt: nucleotides\n",
      "u_score_pe: 0.7787390947341919\n",
      "\n",
      "question: What is an area of land called that is wet for all or part of the year?\n",
      "washed_answer: Wetland\n",
      "input: Question:What is an area of land called that is wet for all or part of the year? Options:plains, wetland, grassland, tundra Answer:\n",
      "output: Question:What is an area of land called that is wet for all or part of the year? Options:plains, wetland, grassland, tundra Answer:Wetland</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
      "gt: wetland\n",
      "u_score_pe: 2.6591553688049316\n",
      "\n",
      "question: Surface waters are heated by the radiation from?\n",
      "washed_answer: gamma rays\n",
      "input: Question:Surface waters are heated by the radiation from? Options:gamma rays, the sun, the moon, decomposition Answer:\n",
      "output: Question:Surface waters are heated by the radiation from? Options:gamma rays, the sun, the moon, decomposition Answer:gamma rays\n",
      "\n",
      "Question:The process of photosynthesis in plants involves the conversion of? Options:carbon dioxide, water, oxygen, nitrogen\n",
      "Answer:carbon dioxide and water\n",
      "\n",
      "Question:The process of cellular respiration in animals involves the conversion of? Options:carbon dioxide, water, oxygen, nitrogen\n",
      "Answer:carbon dioxide and oxygen\n",
      "\n",
      "Question:The process of transpiration in plants involves the loss of? Options:water, carbon dioxide, oxygen, nitrogen\n",
      "Answer:water\n",
      "\n",
      "gt: the sun\n",
      "u_score_pe: 0.4076341986656189\n",
      "\n",
      "question: What are arteries, veins, and capillaries examples of?\n",
      "washed_answer: blood vessels, organs, muscles, tissue\n",
      "input: Question:What are arteries, veins, and capillaries examples of? Options:blood vessels, organs, muscles, tissue Answer:\n",
      "output: Question:What are arteries, veins, and capillaries examples of? Options:blood vessels, organs, muscles, tissue Answer:blood vessels, organs, muscles, tissue\n",
      "\n",
      "Question:What is the main function of the heart? Options:to pump blood, to pump air, to pump lymph, to pump hormones Answer:to pump blood\n",
      "\n",
      "Question:What is the main function of the lymphatic system? Options:to filter blood, to produce blood cells, to transport oxygen, to transport nutrients Answer:to filter blood\n",
      "\n",
      "Question:What is the main function of the respiratory system? Options:to transport oxygen, to transport carbon dioxide\n",
      "gt: blood vessels\n",
      "u_score_pe: 2.126283884048462\n",
      "\n",
      "question: Biochemical reactions of metabolism include what two general categories?\n",
      "washed_answer: catabolic and anabolic\n",
      "\n",
      "Metabolic reactions can be broadly classified into two categories: catabolic and anabolic reactions.\n",
      "\n",
      "Catabolic reactions break down large molecules into smaller ones, releasing energy in the process. These reactions occur in the cytoplasm and the mitochondria of cells and are responsible for breaking down nutrients into smaller molecules that can be used for energy or for building new molecules. Examples of catabolic reactions include the breakdown of glucose to produce energy in the form of ATP, the\n",
      "input: Question:Biochemical reactions of metabolism include what two general categories? Options:catabolic and anabolic, discrete and telltale, innumerable and anabolic, telltale and anabolic Answer:\n",
      "output: Question:Biochemical reactions of metabolism include what two general categories? Options:catabolic and anabolic, discrete and telltale, innumerable and anabolic, telltale and anabolic Answer:catabolic and anabolic\n",
      "\n",
      "Metabolic reactions can be broadly classified into two categories: catabolic and anabolic reactions.\n",
      "\n",
      "Catabolic reactions break down large molecules into smaller ones, releasing energy in the process. These reactions occur in the cytoplasm and the mitochondria of cells and are responsible for breaking down nutrients into smaller molecules that can be used for energy or for building new molecules. Examples of catabolic reactions include the breakdown of glucose to produce energy in the form of ATP, the\n",
      "gt: catabolic and anabolic\n",
      "u_score_pe: 29.36855125427246\n",
      "\n",
      "question: Compounds with aluminum and silicon are commonly found in the clay fractions of soils derived from what?\n",
      "washed_answer: volcanic ash\n",
      "input: Question:Compounds with aluminum and silicon are commonly found in the clay fractions of soils derived from what? Options:volcanic ash, mineral ash, ground ash, volatile ash Answer:\n",
      "output: Question:Compounds with aluminum and silicon are commonly found in the clay fractions of soils derived from what? Options:volcanic ash, mineral ash, ground ash, volatile ash Answer:volcanic ash\n",
      "\n",
      "Question:What is the name of the process by which water is added to the soil to increase its moisture content? Options:evaporation, transpiration, condensation, precipitation Answer:evaporation\n",
      "\n",
      "Question:What is the name of the process by which water is added to the soil to increase its moisture content? Options:evaporation, transpiration, condensation, precipitation Answer:evaporation\n",
      "\n",
      "Question:What is the name of the process by which water is added to the soil to increase its moisture content? Options\n",
      "gt: volcanic ash\n",
      "u_score_pe: 0.3861221373081207\n",
      "\n",
      "question: What organ has four major regions: the cerebrum, the diencephalon, the stem, and the cerebellum?\n",
      "washed_answer: brain. The brain is the organ that has four major regions: the cerebrum, the diencephalon, the stem, and the cerebellum. The cerebrum is the largest part of the brain and is divided into two hemispheres. It is responsible for controlling voluntary movements, sensory processing, and cognitive functions such as perception, attention, memory, and decision-making. The diencephalon is a region located between the cerebrum and the stem and is involved in the regulation of various bodily functions, including the sleep-wake cycle\n",
      "input: Question:What organ has four major regions: the cerebrum, the diencephalon, the stem, and the cerebellum? Options:liver, heart, lungs, brain Answer:\n",
      "output: Question:What organ has four major regions: the cerebrum, the diencephalon, the stem, and the cerebellum? Options:liver, heart, lungs, brain Answer:brain. The brain is the organ that has four major regions: the cerebrum, the diencephalon, the stem, and the cerebellum. The cerebrum is the largest part of the brain and is divided into two hemispheres. It is responsible for controlling voluntary movements, sensory processing, and cognitive functions such as perception, attention, memory, and decision-making. The diencephalon is a region located between the cerebrum and the stem and is involved in the regulation of various bodily functions, including the sleep-wake cycle\n",
      "gt: brain\n",
      "u_score_pe: 21.402124404907227\n",
      "\n",
      "question: What can refer to a rope in a particular shape and a genetic structure involved in splicing?\n",
      "washed_answer: lariat, braid, noose, tourniquet\n",
      "input: Question:What can refer to a rope in a particular shape and a genetic structure involved in splicing? Options:lariat, braid, noose, tourniquet Answer:\n",
      "output: Question:What can refer to a rope in a particular shape and a genetic structure involved in splicing? Options:lariat, braid, noose, tourniquet Answer:lariat, braid, noose, tourniquet\n",
      "\n",
      "Question:What is the name of the process in which a protein is cut into smaller pieces? Options:translation, transcription, replication, transduction Answer:translation\n",
      "\n",
      "Question:What is the name of the process in which a protein is synthesized from its amino acid sequence? Options:translation, transcription, replication, transduction Answer:translation\n",
      "\n",
      "Question:What is the name of the process in which a DNA molecule is replicated? Options:translation, transcription, replication,\n",
      "gt: lariat\n",
      "u_score_pe: 3.0279083251953125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_dst_case(test_dst):\n",
    "    print(test_dst.column_names)\n",
    "    for i in range(0, 10):\n",
    "        for k in ['question', 'washed_answer','input','output', 'gt', 'u_score_pe']:\n",
    "            print(f\"{k}: {test_dst[i][k]}\")\n",
    "        print()\n",
    "show_dst_case(Dataset.load_from_disk(get_eval_main_result_path('vicuna-7b-v1.1', 'sciq', 'short')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbcb7d017f0b9170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T12:15:14.947296Z",
     "start_time": "2024-04-08T12:15:14.941621Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge Train Dataset\n",
    "model_name = 'vicuna-7b-v1.1'\n",
    "train_size_per_dataset = 2000\n",
    "val_size_per_dataset = 100\n",
    "\n",
    "\n",
    "def merge_dst(model_name, dst_names, dst_types, dst_split, data_size):\n",
    "    all_dst = [Dataset.load_from_disk(get_cached_result_path(model_name, dst_name, dst_type, dst_split)) for dst_name in dst_names for dst_type in dst_types]\n",
    "\n",
    "    all_columns = ['dst_template', 'question', 'input', 'gt', 'options', 'answer', 'output']\n",
    "\n",
    "    def fill_missing_columns(dst: Dataset):\n",
    "        for column in dst.column_names:\n",
    "            if column not in all_columns:\n",
    "                dst = dst.remove_columns(column)\n",
    "        if 'options' not in dst.column_names:\n",
    "            dst = dst.add_column('options', [['#####'] for i in range(len(dst))])\n",
    "        return dst\n",
    "\n",
    "    all_dst = [dst if len(dst) <= data_size else dst.select(range(data_size)) for dst in all_dst]\n",
    "    all_dst = [fill_missing_columns(dst) for dst in all_dst]\n",
    "    merged_dst = datasets.concatenate_datasets(all_dst)\n",
    "    print(len(merged_dst))\n",
    "    save_path = get_cached_result_path(model_name, 'all', 'merged', dst_split)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    merged_dst.save_to_disk(save_path)\n",
    "    print(f\"Save Merged Dataset to {save_path}\")\n",
    "\n",
    "merge_dst(model_name, dst_names, dst_types, 'train', train_size_per_dataset)\n",
    "merge_dst(model_name, dst_names, dst_types, 'validation', val_size_per_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e02693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Results: Get Main Results\n",
    "\n",
    "c_metric = 'include'\n",
    "c_th = 0.3\n",
    "\n",
    "model_names_index = [model_names_alias[name] for name in model_names for i in range(len(dst_names))]\n",
    "dst_names_index = [dst_names_alias[name] for name in dst_names] * len(model_names)\n",
    "multi_index = pd.MultiIndex.from_tuples(zip(model_names_index, dst_names_index), names=['Model', 'Dataset'])\n",
    "columns = ['ACC'] + [alias for u_metric, alias in u_metric_alias.items() if (c_metric in u_metric) or 'ours' not in u_metric]\n",
    "main_results_short = pd.DataFrame(columns=columns, index=multi_index).astype(float)\n",
    "main_results_long = deepcopy(main_results_short)\n",
    "\n",
    "for model_name in model_names:\n",
    "    for dst_name in dst_names:\n",
    "        for dst_type in dst_types:\n",
    "            new_row = {k: 0. for k in main_results_short.columns}\n",
    "            result_path = get_eval_main_result_path(model_name, dst_name, dst_type)\n",
    "            if os.path.exists(result_path):\n",
    "                test_dst = Dataset.load_from_disk(result_path)\n",
    "                new_row['ACC'] = get_acc_by_c_th(test_dst, c_metric, c_th) * 100\n",
    "                for u_metric, u_metric_name in u_metric_alias.items():\n",
    "                    if u_metric_name in columns and u_metric in test_dst.column_names:\n",
    "                        new_row[u_metric_name] = get_auroc(test_dst, u_metric, c_metric, c_th) * 100\n",
    "            result = main_results_short if dst_type == 'short' else main_results_long\n",
    "            result.loc[(model_names_alias[model_name], dst_names_alias[dst_name])] = new_row\n",
    "\n",
    "print(f\"Correctness Metric: {c_metric} Threshold: {c_th} AUROC Results\")\n",
    "print(\"Short Prompt Main Result:\")\n",
    "display(main_results_short)\n",
    "\n",
    "print(\"Long Prompt Main Result:\")\n",
    "display(main_results_long)\n",
    "\n",
    "# print(main_results_short.to_latex(index=True, float_format=\"%.2f\"))\n",
    "# print(main_results_long.to_latex(index=True, float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635415cfed8278ee",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generalization1: Cross Dataset and Cross Prompt Evaluation\n",
    "model_name = 'vicuna-7b-v1.1'\n",
    "\n",
    "\n",
    "def plot_cross_dst_matrix(model_name, u_metric, c_metric, c_th):\n",
    "    fig_index = [(name, type) for type in dst_types for name in dst_names]\n",
    "    fig_axis = list(map(lambda idx: f\"{dst_names_alias[idx[0]]}-{idx[1]}\", fig_index))\n",
    "    cross_eval_matrix = torch.zeros(len(dst_types) * len(dst_names), len(dst_types) * len(dst_names))\n",
    "    fig = go.Figure()\n",
    "    annotations = []\n",
    "\n",
    "    for i, (train_dst_name, train_dst_type) in enumerate(fig_index):\n",
    "        for j, (test_dst_name, test_dst_type) in enumerate(fig_index):\n",
    "            result_path = get_eval_cross_result_path(model_name, train_dst_name, train_dst_type, test_dst_name, test_dst_type, u_metric.split(\"_\")[-1])\n",
    "            if os.path.exists(f\"{result_path}/dataset_info.json\"):\n",
    "                cross_eval_result = Dataset.load_from_disk(result_path)\n",
    "                cross_eval_matrix[j][i] = get_auroc(cross_eval_result, u_metric, c_metric, c_th) * 100\n",
    "                annotations.append(dict(\n",
    "                    x=i,\n",
    "                    y=j,\n",
    "                    text=f\"{cross_eval_matrix[j][i].item():.2f}\",\n",
    "                    showarrow=False,\n",
    "                    font=dict(\n",
    "                        color='white'\n",
    "                    )\n",
    "                ))\n",
    "    fig.add_trace(go.Heatmap(z=cross_eval_matrix, x=fig_axis, y=fig_axis, colorscale='Inferno'))\n",
    "    fig.update_layout(\n",
    "        title_text=f\"Model: {model_names_alias[model_name]} Correctness Metric: {c_metric} Method: {u_metric} Cross Eval Results\",\n",
    "        xaxis_title=\"Train Dataset\",\n",
    "        yaxis_title=\"Test Dataset\",\n",
    "        width=1000,\n",
    "        height=1000,\n",
    "        annotations=annotations\n",
    "    )\n",
    "    fig.show()\n",
    "    overall_average_drop = cross_eval_matrix.mean().item() - cross_eval_matrix.diag().mean().item()\n",
    "    short_average_drop = cross_eval_matrix[:5, :5].mean().item() - cross_eval_matrix[:5, :5].diag().mean().item()\n",
    "    long_average_drop = cross_eval_matrix[5:, 5:].mean().item() - cross_eval_matrix[5:, 5:].diag().mean().item()\n",
    "    cross_dst_average_drop = (short_average_drop + long_average_drop) / 2\n",
    "    cross_prompt_average_drop = 0\n",
    "    for i in range(len(cross_eval_matrix)):\n",
    "        cross_prompt_average_drop += cross_eval_matrix[i][(i + len(cross_eval_matrix) // 2) % len(cross_eval_matrix)].item()\n",
    "    cross_prompt_average_drop /= len(cross_eval_matrix)\n",
    "    print(f\"Overall Average Drop: {overall_average_drop:.2f}\")\n",
    "    print(f\"Short Average Drop: {short_average_drop:.2f}\")\n",
    "    print(f\"Long Average Drop: {long_average_drop:.2f}\")\n",
    "    print(f\"Cross Dst Average Drop: {cross_dst_average_drop:.2f}\")\n",
    "    print(f\"Cross Prompt Average Drop: {cross_prompt_average_drop:.2f}\")\n",
    "    for i in range(len(cross_eval_matrix)):\n",
    "        dst_drop = cross_eval_matrix[:, i].mean().item() - cross_eval_matrix[i, i].item()\n",
    "        print(f\"Train Dst:{fig_axis[i]} Average Drop: {dst_drop:.2f}\")\n",
    "\n",
    "\n",
    "plot_cross_dst_matrix(model_name, u_metric='u_score_ours_mean_soft_rougel', c_metric='include', c_th=0.3)\n",
    "plot_cross_dst_matrix(model_name, u_metric='u_score_ours_mean_soft_include', c_metric='include', c_th=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae1f8fbb39774e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generalization2: Cross Correctness Metric Evaluation\n",
    "model_name = 'vicuna-7b-v1.1'\n",
    "c_th = 0.3\n",
    "\n",
    "c_metric_index = [name for name in c_metrics for i in range(len(dst_names))]\n",
    "dst_names_index = [dst_names_alias[name] for name in dst_names] * len(c_metrics)\n",
    "multi_index = pd.MultiIndex.from_tuples(zip(c_metric_index, dst_names_index), names=['Correctness Metric', 'Dataset'])\n",
    "columns = ['ACC'] + [u for u in u_metric_alias.values() if 'Ours' in u]\n",
    "cross_c_metric_results_short = pd.DataFrame(columns=columns, index=multi_index).astype(float)\n",
    "cross_c_metric_results_long = deepcopy(cross_c_metric_results_short)\n",
    "\n",
    "for dst_type in dst_types:\n",
    "    result = cross_c_metric_results_short if dst_type == 'short' else cross_c_metric_results_long\n",
    "    for c_metric in c_metrics:\n",
    "        for dst_name in dst_names:\n",
    "            new_row = {k: 0. for k in columns}\n",
    "            result_path = get_eval_main_result_path(model_name, dst_name, dst_type)\n",
    "            if os.path.exists(result_path):\n",
    "                test_dst = Dataset.load_from_disk(result_path)\n",
    "                new_row['ACC'] = get_acc_by_c_th(test_dst, c_metric, c_th) * 100\n",
    "                for u_metric, u_metric_name in u_metric_alias.items():\n",
    "                    if u_metric_name in columns and u_metric in test_dst.column_names:\n",
    "                        new_row[u_metric_name] = get_auroc(test_dst, u_metric, c_metric, c_th) * 100\n",
    "            result.loc[(c_metric, dst_names_alias[dst_name])] = new_row\n",
    "\n",
    "print(\"Short Prompt Cross Correctness Metric Result:\")\n",
    "display(cross_c_metric_results_short)\n",
    "\n",
    "print(\"Long Prompt Cross Correctness Metric Result:\")\n",
    "display(cross_c_metric_results_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd8d7aba27e1c5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Efficiency: Get Efficiency Results\n",
    "model_name = 'vicuna-7b-v1.1'\n",
    "dst_name = 'sciq'\n",
    "dst_type = 'long'\n",
    "\n",
    "\n",
    "def plot_efficiency_results(model_name, dst_name, dst_type):\n",
    "    fig = go.Figure()\n",
    "    result_path = get_eval_main_result_path(model_name, dst_name, dst_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d897bab3f385d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Correctness Metric Similarity\n",
    "base_c_metric = \"rougel\"\n",
    "model_name = 'vicuna-7b-v1.1'\n",
    "\n",
    "for dst_name in dst_names:\n",
    "    for dst_type in dst_types:\n",
    "        result_path = get_eval_main_result_path(model_name, dst_name, dst_type)\n",
    "        if os.path.exists(result_path):\n",
    "            test_dst = Dataset.load_from_disk(result_path).select(range(500))\n",
    "            # test_dst = test_dst.add_column(\"idx\", list(range(len(test_dst))))\n",
    "            test_dst = test_dst.sort(base_c_metric)\n",
    "            test_dst = test_dst.map(lambda x: dict(include=x['include'] - 0.04) if x['include'] == 0 else dict(include=x['include'] + 0.04))\n",
    "            test_dst = test_dst.map(lambda x: dict(sentsim=x['sentsim'] + 0.02) if x['sentsim'] > 0.99 else dict(sentsim=x['sentsim']))\n",
    "            # test_dst = test_dst.map(lambda x: dict(rougel=x['rougel']+0.02) if x['rougel'] > 0.99 else dict(rougel=x['rougel']))\n",
    "            fig = go.Figure()\n",
    "            for c_metric in c_metrics:\n",
    "                fig.add_trace(go.Scatter(x=list(range(len(test_dst))), y=test_dst[c_metric], mode='markers', name=c_metric))\n",
    "            fig.update_layout(title_text=f\"Model: {model_names_alias[model_name]} Dataset: {dst_names_alias[dst_name]}-{dst_type} Correctness Metric Similarity\",\n",
    "                              xaxis_title=base_c_metric,\n",
    "                              yaxis_title=\"Other Correctness Metric\",\n",
    "                              width=2000,\n",
    "                              height=1000)\n",
    "            fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b05237749c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged Training: Get Merged Training Eval Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b5388f4cdde32",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ablation Study: Get Ablation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83f82d29861e8a8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sensitivity Analysis : Get Sensitivity Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db69225b79de49",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Case Study: show token level u_score\n",
    "example = test_dst.filter(lambda x: x['rougel'] < 0.1)[1]\n",
    "example = test_dst[2]\n",
    "print(f\"gt:{example['gt']}\")\n",
    "print(f\"options:{example['options']}\")\n",
    "\n",
    "str_tokens = model.to_str_tokens(f\":{example['washed_answer']}\", prepend_bos=False)[1:]\n",
    "fig = make_subplots(rows=2, cols=1, subplot_titles=(\"Token Level\", \"Sentence Level\"), row_heights=[0.5, 0.5])\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(range(len(str_tokens))), y=example['u_score_pe_all'], mode='lines+markers'), row=1, col=1)\n",
    "fig.update_xaxes(title_text='Token', tickvals=list(range(len(str_tokens))), ticktext=str_tokens, row=1, col=1)\n",
    "\n",
    "sentence_u_score_pe_all = []\n",
    "indices = [0] + [i for i, x in enumerate(str_tokens) if x == '.'] + [-1]\n",
    "spans = [(indices[i], indices[i + 1]) for i in range(len(indices) - 1)]\n",
    "print(len(indices))\n",
    "for span in spans:\n",
    "    sentence_score = sum(example['u_score_pe_all'][span[0]:span[1]]) / (span[1] - span[0])\n",
    "    sentence_u_score_pe_all.extend([sentence_score] * (span[1] - span[0]))\n",
    "sentence_u_score_pe_all.append(sentence_u_score_pe_all[-1])\n",
    "# print(str_tokens)\n",
    "for i, sentence in enumerate(example['washed_answer'].split(\".\")):\n",
    "    print(i + 1, sentence.replace(\"\\n\", ' ').strip())\n",
    "# print(len(example['u_score_pe_all']))\n",
    "# print(sentence_u_score_pe_all)\n",
    "# print(len(sentence_u_score_pe_all))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(range(len(str_tokens))), y=sentence_u_score_pe_all, mode='lines+markers'), row=2, col=1)\n",
    "fig.update_xaxes(title_text='Sentence', tickvals=list(range(len(str_tokens))), ticktext=str_tokens, row=2, col=1)\n",
    "\n",
    "fig.update_layout(height=1000, width=2500, margin=dict(l=0, r=0, b=50, t=50), title_text=example['washed_answer'])\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
