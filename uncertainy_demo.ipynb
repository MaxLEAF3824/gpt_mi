{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3ad78fe71283d0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Inplementation of Internal State-based Uncertainty Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b278c24516568ba0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. 数据集预处理：将不同格式的数据集处理成input+gt的格式，方便判断模型的correctness，这一部分的采用固定不可调整的prompt，即Context: Question: Options: Answer:格式\n",
    "2. 生成回复，为每个模型确定一个prompt，一个max_new_tokens数，然后生成回复\n",
    "3. 计算回复部分的correctness指标，判断模型的回复是否正确\n",
    "4. 计算uncertainty指标，包括PE, LN-PE, SAR, Ours\n",
    "5. 计算AUROC，绘制AUROC/Correctness-Threshold曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T07:51:54.048261Z",
     "start_time": "2024-04-01T07:51:41.197959Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "剩余内存: 611.0 G\n",
      "当前主机名是:SH-IDC1-10-140-0-183\n",
      "SH-IDC1-10-140-0-183      Mon Apr  1 15:51:54 2024  525.60.13\n",
      "[0] NVIDIA A100-SXM4-80GB | 56°C, 100 % | 67905 / 81920 MB | gaopeng(67902M)\n",
      "[1] NVIDIA A100-SXM4-80GB | 70°C, 100 % | 67151 / 81920 MB | gaopeng(67148M)\n",
      "[2] NVIDIA A100-SXM4-80GB | 45°C,   0 % | 62893 / 81920 MB | gaopeng(62890M)\n",
      "[3] NVIDIA A100-SXM4-80GB | 48°C,  61 % | 48033 / 81920 MB | sunzeyi(48030M)\n",
      "[4] NVIDIA A100-SXM4-80GB | 27°C,   0 % |     0 / 81920 MB |\n",
      "[5] NVIDIA A100-SXM4-80GB | 58°C,  99 % | 48033 / 81920 MB | sunzeyi(48030M)\n",
      "[6] NVIDIA A100-SXM4-80GB | 44°C,  62 % | 68729 / 81920 MB | gaopeng(68726M)\n",
      "[7] NVIDIA A100-SXM4-80GB | 39°C,  61 % | 68729 / 81920 MB | gaopeng(68726M)\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "datasets.disable_caching()\n",
    "torch.set_grad_enabled(False)\n",
    "print_sys_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a702b3ebfcfa6944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T07:52:16.924289Z",
     "start_time": "2024-04-01T07:51:57.163792Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55b0ef900e14fd389700a0ba72bcb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/petrelfs/guoyiqiu/miniconda3/envs/mi/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model llama-7b-hf into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Model Config\n",
    "model_name = \"vicuna-7b-v1.1\"\n",
    "hooked_transformer_name = \"llama-7b-hf\"\n",
    "hf_model_path = os.path.join(os.environ[\"my_models_dir\"], model_name)\n",
    "hf_tokenizer = AutoTokenizer.from_pretrained(hf_model_path)\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(hf_model_path)\n",
    "\n",
    "model = HookedTransformer.from_pretrained_no_processing(hooked_transformer_name, dtype='bfloat16', hf_model=hf_model, tokenizer=hf_tokenizer, default_padding_side='left')\n",
    "\n",
    "# Aux Models\n",
    "se_bert_name = \"microsoft/deberta-large-mnli\"\n",
    "nli_pipe = pipeline(\"text-classification\", model=se_bert_name, device=0)\n",
    "\n",
    "# sar_bert_name = 'cross-encoder/stsb-roberta-large'\n",
    "# # sar_bert_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "# sar_bert = SentenceTransformer(sar_bert_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df0eeae0abf3ba21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T08:33:42.120915Z",
     "start_time": "2024-04-01T08:33:42.102644Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Who proposed the theory of evolution by natural selection?',\n",
       " 'distractor3': 'Scopes',\n",
       " 'distractor1': 'Linnaeus',\n",
       " 'distractor2': 'shaw',\n",
       " 'correct_answer': 'darwin',\n",
       " 'support': '',\n",
       " 'input': 'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:',\n",
       " 'dst_template': 'Question:{q} Options:{o} Answer:',\n",
       " 'options': ['Scopes', 'shaw', 'darwin', 'Linnaeus'],\n",
       " 'gt': 'darwin',\n",
       " 'answer': 'Darwin, Linnaeus, Scopes, Shaw</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       " 'washed_answer': 'Darwin, Linnaeus, Scopes, Shaw',\n",
       " 'output': 'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin, Linnaeus, Scopes, Shaw</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       " 'washed_output': 'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin, Linnaeus, Scopes, Shaw',\n",
       " 'sampled_answer': [\"Darwin, Linnaeus, Scope and Shaw are all important figures in the history of biology, but they did not propose the theory of evolution by natural selection. The theory of evolution by natural selection was proposed by Charles Darwin in the 19th century. Darwin'<s> The world’s first foldable smartphone from Samsung was launched in February 2020. The Samsung Galaxy Z Fold was followed by the release of the Samsung Galaxy Fold 2 in October 2020. The Samsung Galaxy Z Fold 2 is an improved\",\n",
       "  'Darwin, Linnaeus, Scopes, Shaw</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "  'Charles Darwin</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "  'Charles Darwin</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "  'Darwin</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "  'Charles Darwin</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "  'Darwin, Linnaeus</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "  'Darwin</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "  'Darwin Darwin proposed the theory of evolution by natural selection.</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "  'Darwin\\n\\nQuestion:What is the scientific theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin\\n\\nQuestion:What is the theory of natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin\\n\\nQuestion:What is the scientific theory of evolution? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin\\n\\nQuestion:What is the scientific theory of evolution? Options:Scopes, shaw, darwin, Linna'],\n",
       " 'washed_sampled_answer': [\"Darwin, Linnaeus, Scope and Shaw are all important figures in the history of biology, but they did not propose the theory of evolution by natural selection. The theory of evolution by natural selection was proposed by Charles Darwin in the 19th century. Darwin' The world’s first foldable smartphone from Samsung was launched in February 2020. The Samsung Galaxy Z Fold was followed by the release of the Samsung Galaxy Fold 2 in October 2020. The Samsung Galaxy Z Fold 2 is an improved\",\n",
       "  'Darwin, Linnaeus, Scopes, Shaw',\n",
       "  'Charles Darwin',\n",
       "  'Charles Darwin',\n",
       "  'Darwin',\n",
       "  'Charles Darwin',\n",
       "  'Darwin, Linnaeus',\n",
       "  'Darwin',\n",
       "  'Darwin Darwin proposed the theory of evolution by natural selection.',\n",
       "  'Darwin'],\n",
       " 'sampled_output': [\"Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin, Linnaeus, Scope and Shaw are all important figures in the history of biology, but they did not propose the theory of evolution by natural selection. The theory of evolution by natural selection was proposed by Charles Darwin in the 19th century. Darwin'<s> The world’s first foldable smartphone from Samsung was launched in February 2020. The Samsung Galaxy Z Fold was followed by the release of the Samsung Galaxy Fold 2 in October 2020. The Samsung Galaxy Z Fold 2 is an improved\",\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin, Linnaeus, Scopes, Shaw</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Charles Darwin</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Charles Darwin</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Charles Darwin</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin, Linnaeus</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin Darwin proposed the theory of evolution by natural selection.</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>',\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin\\n\\nQuestion:What is the scientific theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin\\n\\nQuestion:What is the theory of natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin\\n\\nQuestion:What is the scientific theory of evolution? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin\\n\\nQuestion:What is the scientific theory of evolution? Options:Scopes, shaw, darwin, Linna'],\n",
       " 'washed_sampled_output': [\"Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin, Linnaeus, Scope and Shaw are all important figures in the history of biology, but they did not propose the theory of evolution by natural selection. The theory of evolution by natural selection was proposed by Charles Darwin in the 19th century. Darwin' The world’s first foldable smartphone from Samsung was launched in February 2020. The Samsung Galaxy Z Fold was followed by the release of the Samsung Galaxy Fold 2 in October 2020. The Samsung Galaxy Z Fold 2 is an improved\",\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin, Linnaeus, Scopes, Shaw',\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Charles Darwin',\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Charles Darwin',\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin',\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Charles Darwin',\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin, Linnaeus',\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin',\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin Darwin proposed the theory of evolution by natural selection.',\n",
       "  'Question:Who proposed the theory of evolution by natural selection? Options:Scopes, shaw, darwin, Linnaeus Answer:Darwin'],\n",
       " 'num_input_tokens': 30,\n",
       " 'num_output_tokens': 43,\n",
       " 'num_answer_tokens': 13,\n",
       " 'answer_idxs': [-14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1],\n",
       " 'rougel': 0.0,\n",
       " 'sentsim': 0.8348510265350342,\n",
       " 'answer_prob': [0.39453125,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.46875,\n",
       "  0.296875,\n",
       "  0.99609375,\n",
       "  1.0,\n",
       "  0.466796875,\n",
       "  0.43359375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9296875,\n",
       "  0.71875],\n",
       " 'time_fwd': 0.018756240606307983,\n",
       " 'sampled_answer_prob': [[0.390625,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.486328125,\n",
       "   0.287109375,\n",
       "   0.99609375,\n",
       "   1.0,\n",
       "   0.48828125,\n",
       "   0.2099609375,\n",
       "   0.97265625,\n",
       "   0.03125,\n",
       "   0.98046875,\n",
       "   0.84375,\n",
       "   0.6484375,\n",
       "   0.140625,\n",
       "   0.64453125,\n",
       "   0.98046875,\n",
       "   0.6796875,\n",
       "   0.7734375,\n",
       "   0.9765625,\n",
       "   0.41015625,\n",
       "   0.99609375,\n",
       "   0.62109375,\n",
       "   0.953125,\n",
       "   0.1611328125,\n",
       "   0.66015625,\n",
       "   0.9921875,\n",
       "   0.96484375,\n",
       "   0.99609375,\n",
       "   0.99609375,\n",
       "   0.99609375,\n",
       "   1.0,\n",
       "   0.96875,\n",
       "   0.99609375,\n",
       "   0.99609375,\n",
       "   0.984375,\n",
       "   0.6640625,\n",
       "   0.9921875,\n",
       "   0.984375,\n",
       "   0.99609375,\n",
       "   0.98828125,\n",
       "   0.99609375,\n",
       "   0.99609375,\n",
       "   0.96875,\n",
       "   0.79296875,\n",
       "   0.9921875,\n",
       "   0.9140625,\n",
       "   0.9765625,\n",
       "   1.0,\n",
       "   0.6171875,\n",
       "   0.53515625,\n",
       "   0.72265625,\n",
       "   1.0,\n",
       "   0.89453125,\n",
       "   0.99609375,\n",
       "   0.98828125,\n",
       "   0.7265625,\n",
       "   0.08984375,\n",
       "   1.0,\n",
       "   0.53515625,\n",
       "   1.9669532775878906e-05,\n",
       "   2.0742416381835938e-05,\n",
       "   0.000621795654296875,\n",
       "   0.984375,\n",
       "   0.0673828125,\n",
       "   5.9604644775390625e-05,\n",
       "   0.365234375,\n",
       "   0.96875,\n",
       "   0.0130615234375,\n",
       "   0.92578125,\n",
       "   0.03271484375,\n",
       "   0.041259765625,\n",
       "   0.98828125,\n",
       "   0.01397705078125,\n",
       "   0.490234375,\n",
       "   0.875,\n",
       "   0.014892578125,\n",
       "   0.81640625,\n",
       "   0.9921875,\n",
       "   0.99609375,\n",
       "   0.8671875,\n",
       "   0.57421875,\n",
       "   0.58984375,\n",
       "   0.1220703125,\n",
       "   0.19921875,\n",
       "   0.93359375,\n",
       "   0.52734375,\n",
       "   1.0,\n",
       "   0.80078125,\n",
       "   0.9921875,\n",
       "   1.0,\n",
       "   0.2041015625,\n",
       "   0.00396728515625,\n",
       "   0.9765625,\n",
       "   0.83203125,\n",
       "   0.11328125,\n",
       "   0.98828125,\n",
       "   0.77734375,\n",
       "   0.455078125,\n",
       "   0.890625,\n",
       "   0.97265625,\n",
       "   1.0,\n",
       "   0.32421875,\n",
       "   1.0,\n",
       "   0.9453125,\n",
       "   0.98046875,\n",
       "   0.65625,\n",
       "   0.2060546875,\n",
       "   0.90234375,\n",
       "   1.0,\n",
       "   0.99609375,\n",
       "   1.0,\n",
       "   0.96875,\n",
       "   0.91015625,\n",
       "   0.314453125,\n",
       "   0.224609375,\n",
       "   0.9921875,\n",
       "   0.9375,\n",
       "   1.0,\n",
       "   0.640625,\n",
       "   0.99609375,\n",
       "   1.0,\n",
       "   0.828125,\n",
       "   1.0,\n",
       "   0.734375,\n",
       "   0.10888671875,\n",
       "   0.05712890625],\n",
       "  [0.390625,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.486328125,\n",
       "   0.287109375,\n",
       "   0.99609375,\n",
       "   1.0,\n",
       "   0.48828125,\n",
       "   0.4453125,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.92578125,\n",
       "   0.69921875],\n",
       "  [0.267578125, 1.0, 0.9375, 1.0],\n",
       "  [0.267578125, 1.0, 0.9375, 1.0],\n",
       "  [0.390625, 1.0, 1.0],\n",
       "  [0.267578125, 1.0, 0.9375, 1.0],\n",
       "  [0.390625, 1.0, 1.0, 0.486328125, 0.287109375, 0.99609375, 1.0],\n",
       "  [0.390625, 1.0, 1.0],\n",
       "  [0.390625,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.07958984375,\n",
       "   0.9921875,\n",
       "   0.33203125,\n",
       "   0.984375,\n",
       "   0.99609375,\n",
       "   0.9921875,\n",
       "   0.9921875,\n",
       "   0.98828125,\n",
       "   0.9921875,\n",
       "   0.99609375,\n",
       "   0.2353515625],\n",
       "  [0.390625, 1.0, 1.0]],\n",
       " 'u_score_len': 0.4583715371652497,\n",
       " 'u_score_pe_all': [0.9300569295883179,\n",
       "  -0.0,\n",
       "  -0.0,\n",
       "  0.7576857209205627,\n",
       "  1.2144441604614258,\n",
       "  0.003913899417966604,\n",
       "  -0.0,\n",
       "  0.7618610858917236,\n",
       "  0.8356472253799438,\n",
       "  -0.0,\n",
       "  -0.0,\n",
       "  0.07290676981210709,\n",
       "  0.33024168014526367],\n",
       " 'u_score_pe': 0.5376189238355153,\n",
       " 'u_score_ln_pe': 0.5838901195721101,\n",
       " 'time_pe': 0.00043451786041259766,\n",
       " 'u_score_token_sar': 0.5149803655805337,\n",
       " 'time_token_sar': 0.030808448791503906,\n",
       " 'time_sent_sar': 0.010897159576416016,\n",
       " 'time_sar': 0.23959040641784668,\n",
       " 'u_score_sent_sar': 0.4600530648483192,\n",
       " 'u_score_sar': 0.5089614574433997,\n",
       " 'u_score_ls': 0.007902328671755554,\n",
       " 'time_ls': 0.004051685333251953,\n",
       " 'u_score_se': 0.9184820517912551,\n",
       " 'time_se': 2.115844249725342,\n",
       " 'u_score_ours_mean_soft': -0.04866962946108222,\n",
       " 'time_ours_mean_soft': 0.012522906064987183,\n",
       " 'u_score_ours_mean_hard': -0.033118080632234204,\n",
       " 'time_ours_mean_hard': 0.007790416479110718,\n",
       " 'u_score_ours_last_soft': -0.24769944406010957,\n",
       " 'time_ours_last_soft': 0.008896827697753906,\n",
       " 'u_score_ours_last_hard': -0.4697115109101089,\n",
       " 'time_ours_last_hard': 0.013115078210830688}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst_name = \"sciq\"\n",
    "dst_type = \"short\"\n",
    "test_dst = Dataset.load_from_disk(f\"eval_results/{model_name}/{dst_name}_{dst_type}\")\n",
    "test_dst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "88edd9cca2e9bbfb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Our Method OLD\n",
    "def compute_certainty_vector_mean(train_dst, layers, act_name, batch_size=8):\n",
    "    def get_paired_dst_sciq(train_dst):\n",
    "        tmp_pos = \"Question:{q} Options:{o} The correct answer is:\"\n",
    "        tmp_neg = \"Question:{q} Options:{o} The incorrect answer is:\"\n",
    "    \n",
    "        # sciq_train_dst = sciq_train_dst.filter(lambda x: x['rougel'] > 0.5)\n",
    "    \n",
    "        def get_pos_example(example):\n",
    "            example['input'] = tmp_pos.format(q=example['question'], o=\", \".join(example['options']))\n",
    "            example['washed_output'] = f\"{example['input']}{example['gt']}\"\n",
    "            return example\n",
    "    \n",
    "        def get_neg_example(example, idx):\n",
    "            example['input'] = tmp_neg.format(q=example['question'], o=\", \".join(example['options']))\n",
    "            wrong_options = [opt for opt in example['options'] if opt != example['gt']]\n",
    "            if wrong_options:\n",
    "                random.seed(42 + idx)\n",
    "                wrong_answer = random.choice(wrong_options)\n",
    "            else:\n",
    "                wrong_answer = \"wrong answer\"\n",
    "            example['washed_output'] = f\"{example['input']}{wrong_answer}\"\n",
    "            return example\n",
    "    \n",
    "        dst_pos = train_dst.map(get_pos_example, new_fingerprint=str(time()))\n",
    "        dst_neg = train_dst.map(get_neg_example, with_indices=True, new_fingerprint=str(time()))\n",
    "        return dst_pos, dst_neg\n",
    "    \n",
    "    \n",
    "    def get_paired_dst_coqa(train_dst):\n",
    "        def get_pos_example(example):\n",
    "            example['washed_output'] = f\"{example['input']}The correct answer is {example['gt']}\"\n",
    "            return example\n",
    "    \n",
    "        def get_neg_example(example, idx):\n",
    "            wrong_options = [opt for opt in example['answers']['input_text'] if opt != example['gt']]\n",
    "            if wrong_options:\n",
    "                random.seed(42 + idx)\n",
    "                wrong_answer = random.choice(wrong_options)\n",
    "            else:\n",
    "                wrong_answer = \"wrong answer\"\n",
    "            example['washed_output'] = f\"{example['input']}The wrong answer is {wrong_answer}\"\n",
    "            return example\n",
    "    \n",
    "        dst_pos = train_dst.map(get_pos_example, new_fingerprint=str(time()))\n",
    "        dst_neg = train_dst.map(get_neg_example, with_indices=True, new_fingerprint=str(time()))\n",
    "        return dst_pos, dst_neg\n",
    "    \n",
    "    \n",
    "    def get_paired_dst_triviaqa(train_dst):\n",
    "        def get_pos_example(example):\n",
    "            example['washed_output'] = f\"{example['input']}The correct answer is {example['gt']}\"\n",
    "            return example\n",
    "    \n",
    "        def get_neg_example(example, idx):\n",
    "            next_idx = idx + 1 if idx + 1 < len(train_dst) else 0\n",
    "            wrong_answer = train_dst[next_idx]['gt']\n",
    "            example['washed_output'] = f\"{example['input']}The wrong answer is {wrong_answer}\"\n",
    "            return example\n",
    "    \n",
    "        dst_pos = train_dst.map(get_pos_example, new_fingerprint=str(time()))\n",
    "        dst_neg = train_dst.map(get_neg_example, with_indices=True, new_fingerprint=str(time()))\n",
    "        return dst_pos, dst_neg\n",
    "    \n",
    "    \n",
    "    def get_paired_dst_medmcqa(train_dst):\n",
    "        def get_pos_example(example):\n",
    "            example['washed_output'] = f\"{example['input']}The correct answer is {example['gt']}\"\n",
    "            return example\n",
    "    \n",
    "        def get_neg_example(example, idx):\n",
    "            wrong_options = [opt for opt in example['options'] if opt != example['gt']]\n",
    "            if wrong_options:\n",
    "                random.seed(42 + idx)\n",
    "                wrong_answer = random.choice(wrong_options)\n",
    "            else:\n",
    "                wrong_answer = \"wrong answer\"\n",
    "            example['washed_output'] = f\"{example['input']}The wrong answer is {wrong_answer}\"\n",
    "            return example\n",
    "    \n",
    "        dst_pos = train_dst.map(get_pos_example, new_fingerprint=str(time()))\n",
    "        dst_neg = train_dst.map(get_neg_example, with_indices=True, new_fingerprint=str(time()))\n",
    "        return dst_pos, dst_neg\n",
    "    \n",
    "    func_map = {\n",
    "        'allenai/sciq': get_paired_dst_sciq,\n",
    "        'stanfordnlp/coqa': get_paired_dst_coqa,\n",
    "        'lucadiliello/triviaqa': get_paired_dst_triviaqa,\n",
    "        'openlifescienceai/medmcqa': get_paired_dst_medmcqa,\n",
    "        'GBaker/MedQA-USMLE-4-options': get_paired_dst_medmcqa\n",
    "    }\n",
    "    func = func_map[dst_name]\n",
    "    dst_pos, dst_neg = func(train_dst)\n",
    "    \n",
    "    data_pos = dst_pos['washed_output']\n",
    "    data_neg = dst_neg['washed_output']\n",
    "    data_size = len(data_pos)\n",
    "    full_act_names = [utils.get_act_name(act_name, l) for l in sorted(layers)]\n",
    "    v_c = torch.zeros((len(layers), 1, model.cfg.d_model)).cuda()\n",
    "\n",
    "    for i in tqdm(range(0, data_size, batch_size)):\n",
    "        batch_pos = data_pos[i:i + batch_size]\n",
    "        batch_neg = data_neg[i:i + batch_size]\n",
    "\n",
    "        _, cache_pos = model.run_with_cache(batch_pos, names_filter=lambda x: x in full_act_names, padding_side='left')  # logits: (bsz pos vocab) cache: dict\n",
    "        _, cache_neg = model.run_with_cache(batch_neg, names_filter=lambda x: x in full_act_names, padding_side='left')  # logits: (bsz pos vocab) cache: dict\n",
    "\n",
    "        cache_pos = einops.rearrange([cache_pos[name] for name in full_act_names], 'l b p d -> b l p d')\n",
    "        cache_neg = einops.rearrange([cache_neg[name] for name in full_act_names], 'l b p d -> b l p d')\n",
    "\n",
    "        cache_pos = cache_pos[:, :, [-1], :]\n",
    "        cache_neg = cache_neg[:, :, [-1], :]\n",
    "\n",
    "        v_c += (cache_pos.sum(dim=0) - cache_neg.sum(dim=0))\n",
    "\n",
    "    v_c /= data_size\n",
    "\n",
    "    v_c = v_c.cpu().float()\n",
    "    v_c = F.normalize(v_c, p=2, dim=-1)\n",
    "    return v_c\n",
    "\n",
    "# clean_exp exp\n",
    "def clean_exp(dst, v_c, layers, act_name):\n",
    "    fig = go.Figure()\n",
    "    c_scores = []\n",
    "    w_scores = []\n",
    "    labels = []\n",
    "    u_scores = []\n",
    "    u_scores_z = []\n",
    "    all_pe_u_scores = []\n",
    "    all_ln_pe_u_scores = []\n",
    "\n",
    "    def batch_get_result(examples):\n",
    "        all_outputs = []\n",
    "        all_num_answer_tokens = []\n",
    "        all_num_input_tokens = list(map(len, model.to_str_tokens(examples['input'])))\n",
    "        bsz = len(examples['input'])\n",
    "\n",
    "        for i in range(bsz):\n",
    "            example = {k: examples[k][i] for k in examples.keys()}\n",
    "            if example.get(\"options\"):\n",
    "                wrong_options = [opt for opt in example['options']]\n",
    "                for opt in wrong_options:\n",
    "                    if opt == example['gt']:\n",
    "                        wrong_options.remove(opt)\n",
    "                        break\n",
    "            elif example.get(\"answers\"):\n",
    "                wrong_options = [opt for opt in example['answers']['input_text']]\n",
    "                for opt in wrong_options:\n",
    "                    if opt == example['gt']:\n",
    "                        wrong_options.remove(opt)\n",
    "                        break\n",
    "                wrong_options = wrong_options[:3]\n",
    "            else:\n",
    "                wrong_options = ['wrong answer', 'bad answer', 'incorrect answer']\n",
    "            correct_output = example['input'] + example['gt']\n",
    "            wrong_outputs = [example['input'] + opt for opt in wrong_options]\n",
    "            all_outputs.extend([correct_output] + wrong_outputs)\n",
    "            num_answer_tokens = list(map(len, model.to_str_tokens([example['gt']] + wrong_options)))\n",
    "            all_num_answer_tokens.append(num_answer_tokens)\n",
    "\n",
    "        full_act_names = [utils.get_act_name(act_name, l) for l in sorted(layers)]\n",
    "\n",
    "        batch_logits, batch_cache = model.run_with_cache(all_outputs, names_filter=lambda x: x in full_act_names,\n",
    "                                                         device='cpu',\n",
    "                                                         padding_side='left')  # logits: (bsz pos vocab) cache: dict\n",
    "        batch_cache = einops.rearrange([batch_cache[name] for name in full_act_names],\n",
    "                                       'l b p d -> b l p d').float().cpu()\n",
    "        batch_cache = einops.rearrange(batch_cache, '(b o) l p d -> b o l p d', o=4)\n",
    "        batch_cache = batch_cache[:, :, :, [-1], :]\n",
    "\n",
    "        batch_logits = batch_logits.cpu().float()\n",
    "        batch_logits = einops.rearrange(batch_logits, '(b o) p v -> b o p v', o=4)\n",
    "\n",
    "        for i, lg_4 in enumerate(batch_logits):\n",
    "            num_answer_tokens = all_num_answer_tokens[i]\n",
    "            num_input_tokens = all_num_input_tokens[i]\n",
    "            for j, lg in enumerate(lg_4):\n",
    "                output = all_outputs[i * 4 + j]\n",
    "                answer_lg = lg[-num_answer_tokens[j] - 1:-1]\n",
    "                answer_prob = F.softmax(answer_lg, dim=-1)\n",
    "                answer_target_prob = answer_prob.max(dim=-1).values\n",
    "                pe = -torch.log(answer_target_prob).sum().item()\n",
    "                # print(f\"pe:{pe}\")\n",
    "                ln_pe = -torch.log(answer_target_prob).mean().item()\n",
    "                # print(f\"ln_pe:{ln_pe}\")\n",
    "                all_pe_u_scores.append(pe)\n",
    "                all_ln_pe_u_scores.append(ln_pe)\n",
    "\n",
    "        batch_in_vivo_auroc = []\n",
    "        for i in range(bsz):\n",
    "            cache = batch_cache[i]\n",
    "            u_score = einsum('b l p d, l p d -> b', cache, v_c)\n",
    "            u_score_z = (u_score - u_score.mean()) / u_score.std()\n",
    "\n",
    "            u_score = u_score.tolist()\n",
    "            u_score_z = u_score_z.tolist()\n",
    "\n",
    "            in_vivo_auroc = roc_auc_score([1, 0, 0, 0], u_score)\n",
    "            batch_in_vivo_auroc.append(in_vivo_auroc)\n",
    "            # if u_score[0] > max(u_score[1:]):\n",
    "            #     batch_in_vivo_auroc.append(1)\n",
    "            # else:\n",
    "            #     batch_in_vivo_auroc.append(0)\n",
    "\n",
    "            c_scores.append(u_score_z[0])\n",
    "            w_scores.extend(u_score_z[1:])\n",
    "            labels.extend([1, 0, 0, 0])\n",
    "\n",
    "            # assert len(u_score) == 4, f\"{len(u_score)} {example['options']}\"\n",
    "            u_scores.extend(u_score)\n",
    "            u_scores_z.extend(u_score_z)\n",
    "\n",
    "        examples['in_vivo_auroc'] = batch_in_vivo_auroc\n",
    "        return examples\n",
    "\n",
    "    new_dst = dst.map(batch_get_result, new_fingerprint=str(time()), batched=True, batch_size=4)\n",
    "\n",
    "    in_vivo_auroc = sum(new_dst['in_vivo_auroc']) / len(new_dst['in_vivo_auroc'])\n",
    "    flag = in_vivo_auroc > 0.5\n",
    "    in_vivo_auroc = in_vivo_auroc if flag else 1 - in_vivo_auroc\n",
    "    print(f\"in-vivo u_score auroc: {in_vivo_auroc}\")\n",
    "\n",
    "    in_vitro_auroc = roc_auc_score(labels, u_scores)\n",
    "    in_vitro_auroc = in_vitro_auroc if flag else 1 - in_vitro_auroc\n",
    "    print(f\"in-vitro u_score auroc: {in_vitro_auroc}\")\n",
    "\n",
    "    in_vitro_auroc_z = roc_auc_score(labels, u_scores_z)\n",
    "    in_vitro_auroc_z = in_vitro_auroc_z if flag else 1 - in_vitro_auroc_z\n",
    "    print(f\"in-vitro u_score_z auroc: {in_vitro_auroc_z}\")\n",
    "\n",
    "    in_vitro_pe_auroc = roc_auc_score(labels, all_pe_u_scores)\n",
    "    print(f\"in-vitro pe auroc: {in_vitro_pe_auroc}\")\n",
    "\n",
    "    in_vitro_ln_pe_auroc = roc_auc_score(labels, all_ln_pe_u_scores)\n",
    "    print(f\"in-vitro ln_pe auroc: {in_vitro_ln_pe_auroc}\")\n",
    "\n",
    "    fig.add_trace(go.Histogram(x=c_scores, name='Correct', opacity=0.5, nbinsx=100))\n",
    "    fig.add_trace(go.Histogram(x=w_scores, name='Wrong', opacity=0.5, nbinsx=100))\n",
    "    fig.update_layout(barmode='overlay')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a9129651081dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-24T14:31:25.812191Z",
     "start_time": "2024-03-24T14:31:25.124814Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u_metrics = [k for k in test_dst[0].keys() if k.startswith(\"u_score\") and not k.endswith(\"all\")]\n",
    "fig = plot_th_curve(test_dst, u_metrics, 'rougel')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db69225b79de49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T15:20:35.189620Z",
     "start_time": "2024-03-21T15:20:35.065244Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example = test_dst.filter(lambda x: x['rougel'] < 0.1)[1]\n",
    "example = test_dst[2]\n",
    "print(f\"gt:{example['gt']}\")\n",
    "print(f\"options:{example['options']}\")\n",
    "\n",
    "str_tokens = model.to_str_tokens(f\":{example['washed_answer']}\", prepend_bos=False)[1:]\n",
    "fig = make_subplots(rows=2, cols=1, subplot_titles=(\"Token Level\", \"Sentence Level\"), row_heights=[0.5, 0.5])\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(range(len(str_tokens))), y=example['u_score_pe_all'], mode='lines+markers'), row=1, col=1)\n",
    "fig.update_xaxes(title_text='Token', tickvals=list(range(len(str_tokens))), ticktext=str_tokens, row=1, col=1)\n",
    "\n",
    "sentence_u_score_pe_all = []\n",
    "indices = [0]+[i for i, x in enumerate(str_tokens) if x == '.']+[-1]\n",
    "spans = [(indices[i], indices[i+1]) for i in range(len(indices)-1)]\n",
    "print(len(indices))\n",
    "for span in spans:\n",
    "    sentence_score = sum(example['u_score_pe_all'][span[0]:span[1]]) / (span[1] - span[0])\n",
    "    sentence_u_score_pe_all.extend([sentence_score] * (span[1] - span[0]))\n",
    "sentence_u_score_pe_all.append(sentence_u_score_pe_all[-1])\n",
    "# print(str_tokens)\n",
    "for i, sentence in enumerate(example['washed_answer'].split(\".\")):\n",
    "    print(i+1,sentence.replace(\"\\n\",' ').strip())\n",
    "# print(len(example['u_score_pe_all']))\n",
    "# print(sentence_u_score_pe_all)\n",
    "# print(len(sentence_u_score_pe_all))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(range(len(str_tokens))), y=sentence_u_score_pe_all, mode='lines+markers'), row=2, col=1)\n",
    "fig.update_xaxes(title_text='Sentence', tickvals=list(range(len(str_tokens))), ticktext=str_tokens, row=2, col=1)\n",
    "\n",
    "fig.update_layout(height=1000, width=2500, margin=dict(l=0, r=0, b=50, t=50), title_text=example['washed_answer'])\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
